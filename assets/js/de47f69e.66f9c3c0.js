"use strict";(self.webpackChunkstarrocks=self.webpackChunkstarrocks||[]).push([[70425],{17162:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>c});var i=t(85893),a=t(11151);const s={},r="Data distribution",o={id:"table_design/Data_distribution",title:"Data distribution",description:"Configuring appropriate partitioning and bucketing at table creation can help to achieve even data distribution. Even data distribution means dividing the data into subsets according to certain rules and distributing them evenly across different nodes. It can also reduce the amount of data scanned and make full use of the cluster's parallel processing capability, thereby improving query performance.",source:"@site/versioned_docs/version-3.1/table_design/Data_distribution.md",sourceDirName:"table_design",slug:"/table_design/Data_distribution",permalink:"/docusaurusv3/docs/latest/table_design/Data_distribution",draft:!1,unlisted:!1,editUrl:"https://github.com/StarRocks/starrocks/tree/main/versioned_docs/version-3.1/table_design/Data_distribution.md",tags:[],version:"3.1",frontMatter:{},sidebar:"documentation",previous:{title:"Primary Key table",permalink:"/docusaurusv3/docs/latest/table_design/table_types/primary_key_table"},next:{title:"Expression partitioning (recommended)",permalink:"/docusaurusv3/docs/latest/table_design/expression_partitioning"}},d={},c=[{value:"Distribution methods",id:"distribution-methods",level:2},{value:"Distribution methods in general",id:"distribution-methods-in-general",level:3},{value:"Distribution methods in StarRocks",id:"distribution-methods-in-starrocks",level:3},{value:"Partitioning",id:"partitioning",level:4},{value:"How to choose partitioning columns and granularity",id:"how-to-choose-partitioning-columns-and-granularity",level:5},{value:"Bucketing",id:"bucketing",level:4},{value:"Create and manage partitions",id:"create-and-manage-partitions",level:2},{value:"Create partitions",id:"create-partitions",level:3},{value:"Expression partitioning (recommended)",id:"expression-partitioning-recommended",level:4},{value:"Range partitioning",id:"range-partitioning",level:4},{value:"Dynamic partitioning",id:"dynamic-partitioning",level:5},{value:"Manually create partitions",id:"manually-create-partitions",level:5},{value:"Create multiple partitions in batch",id:"create-multiple-partitions-in-batch",level:5},{value:"Create multiple partitions in batch after a table is created",id:"create-multiple-partitions-in-batch-after-a-table-is-created",level:5},{value:"List partitioning (since v3.1)",id:"list-partitioning-since-v31",level:4},{value:"Manage  partitions",id:"manage--partitions",level:3},{value:"Add partitions",id:"add-partitions",level:4},{value:"Delete a partition",id:"delete-a-partition",level:4},{value:"Restore a partition",id:"restore-a-partition",level:4},{value:"View partitions",id:"view-partitions",level:4},{value:"Configure bucketing",id:"configure-bucketing",level:2},{value:"Random bucketing (since v3.1)",id:"random-bucketing-since-v31",level:3},{value:"Limits",id:"limits",level:4},{value:"Hash bucketing",id:"hash-bucketing",level:3},{value:"Advantages",id:"advantages",level:4},{value:"How to choose the bucketing columns",id:"how-to-choose-the-bucketing-columns",level:4},{value:"Precautions",id:"precautions",level:4},{value:"Examples",id:"examples",level:4},{value:"Determine the number of buckets",id:"determine-the-number-of-buckets",level:3}];function l(e){const n=Object.assign({h1:"h1",p:"p",blockquote:"blockquote",strong:"strong",ul:"ul",li:"li",a:"a",h2:"h2",h3:"h3",img:"img",table:"table",thead:"thead",tr:"tr",th:"th",tbody:"tbody",td:"td",pre:"pre",code:"code",h4:"h4",h5:"h5"},(0,a.ah)(),e.components);return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"data-distribution",children:"Data distribution"}),"\n",(0,i.jsx)(n.p,{children:"Configuring appropriate partitioning and bucketing at table creation can help to achieve even data distribution. Even data distribution means dividing the data into subsets according to certain rules and distributing them evenly across different nodes. It can also reduce the amount of data scanned and make full use of the cluster's parallel processing capability, thereby improving query performance."}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"NOTE"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Since v3.1, you do not need to specify the bucketing key in the DISTRIBUTED BY clause when creating a table or adding a partition. StarRocks supports random bucketing, which randomly distributes data across all buckets. For more information, see ",(0,i.jsx)(n.a,{href:"#random-bucketing-since-v31",children:"Random bucketing"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["Since v2.5.7, you can choose not to manually set the number of buckets when you create a table or add a partition. StarRocks can automatically set the number of buckets (BUCKETS). However, if the performance does not meet your expectations after StarRocks automatically sets the number of buckets and you are familiar with the bucketing mechanism, you can still ",(0,i.jsx)(n.a,{href:"#determine-the-number-of-buckets",children:"manually set the number of buckets"}),"."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"distribution-methods",children:"Distribution methods"}),"\n",(0,i.jsx)(n.h3,{id:"distribution-methods-in-general",children:"Distribution methods in general"}),"\n",(0,i.jsx)(n.p,{children:"Modern distributed database systems generally use the following basic distribution methods: Round-Robin, Range, List, and Hash."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Data distribution method",src:t(54270).Z+"",width:"1599",height:"1503"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Round-Robin"}),": distributes data across different nodes in a cyclic."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Range"}),": distributes data across different nodes based on the ranges of partitioning column values. As shown in the diagram, the ranges [1-3] and [4-6] correspond to different nodes."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"List"}),": distributes data across different nodes based on the discrete values of partitioning columns, such as gender and province. Each discrete value is mapped to a node, and multiple different values might be mapped to the same node."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Hash"}),": distributes data across different nodes based on a hash function."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"To achieve more flexible data partitioning, in addition to using one of the above data distribution methods, you can also combine these methods based on specific business requirements. Common combinations include Hash+Hash, Range+Hash, and Hash+List."}),"\n",(0,i.jsx)(n.h3,{id:"distribution-methods-in-starrocks",children:"Distribution methods in StarRocks"}),"\n",(0,i.jsx)(n.p,{children:"StarRocks supports both separate and composite use of data distribution methods."}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"NOTE"})}),"\n",(0,i.jsx)(n.p,{children:"In addition to the general distribution methods, StarRocks also supports Random distribution to simplify bucketing configuration."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Also, StarRocks distributes data by implementing the two-level partitioning + bucketing method."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"The first level is partitioning: Data within a table can be partitioned. Supported partitioning methods are expression partitioning, range partitioning, and list partitioning. Or you can choose not to use partitioning (the entire table is regarded as one partition)."}),"\n",(0,i.jsx)(n.li,{children:"The second level is bucketing: Data in a partition needs to be further distributed into smaller buckets. Supported bucketing methods are hash and random bucketing."}),"\n"]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Distribution method"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Partitioning and bucketing method"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Description"})})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Random distribution"}),(0,i.jsx)(n.td,{children:"Random bucketing"}),(0,i.jsx)(n.td,{children:"The entire table is considered a partition. The data in the table is randomly distributed into different buckets. This is the default data distribution method."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Hash distribution"}),(0,i.jsx)(n.td,{children:"Hash bucketing"}),(0,i.jsx)(n.td,{children:"The entire table is considered a partition. The data in the table is distributed to the corresponding buckets, which is based on the hash values of the data's bucketing key by using a hash function."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Range+Random distribution"}),(0,i.jsx)(n.td,{children:(0,i.jsxs)("ol",{children:[(0,i.jsx)("li",{children:"Expression partitioning or range partitioning "}),(0,i.jsx)("li",{children:"Random bucketing "})]})}),(0,i.jsx)(n.td,{children:(0,i.jsxs)("ol",{children:[(0,i.jsx)("li",{children:"The data in the table is distributed to the corresponding partitions, which is based on the ranges where partitioning column values fall in. "}),(0,i.jsx)("li",{children:"The data in the partition is randomly distributed across different buckets. "})]})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Range+Hash distribution"}),(0,i.jsx)(n.td,{children:(0,i.jsxs)("ol",{children:[(0,i.jsx)("li",{children:"Expression partitioning or range partitioning"}),(0,i.jsx)("li",{children:"Hash bucketing "})]})}),(0,i.jsx)(n.td,{children:(0,i.jsxs)("ol",{children:[(0,i.jsx)("li",{children:"The data in the table is distributed to the corresponding partitions, which is based on the ranges where partitioning column values fall in."}),(0,i.jsx)("li",{children:"The data in the partition is distributed to the corresponding buckets, which is based on the hash values of the data's bucketing key by using a hash function. "})]})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"List+Random distribution"}),(0,i.jsx)(n.td,{children:(0,i.jsxs)("ol",{children:[(0,i.jsx)("li",{children:"Expression partitioning or range partitioning"}),(0,i.jsx)("li",{children:"Random bucketing "})]})}),(0,i.jsx)(n.td,{children:(0,i.jsxs)("ol",{children:[(0,i.jsx)("li",{children:"The data in the table is distributed to the corresponding partitions, which is based on the ranges where partitioning column values fall in."}),(0,i.jsx)("li",{children:"The data in the partition is randomly distributed across different buckets."})]})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"List+Hash distribution"}),(0,i.jsx)(n.td,{children:(0,i.jsxs)("ol",{children:[(0,i.jsx)("li",{children:"Expression partitioning or List partitioning"}),(0,i.jsx)("li",{children:"Hash bucketing "})]})}),(0,i.jsx)(n.td,{children:(0,i.jsxs)("ol",{children:[(0,i.jsx)("li",{children:"The data in the table is partitioned based on the value lists that the partitioning columns values belongs to."}),(0,i.jsx)("li",{children:"The data in the partition is distributed to the corresponding buckets, which is based on the hash values of the data's bucketing key by using a hash function."})]})})]})]})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Random distribution"})}),"\n",(0,i.jsx)(n.p,{children:"If you do not configure partitioning and bucketing methods at table creation, random distribution is used by default. This distribution method currently can only be used to create a Duplicate Key table."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"CREATE TABLE site_access1 (\n    event_day DATE,\n    site_id INT DEFAULT '10', \n    pv BIGINT DEFAULT '0' ,\n    city_code VARCHAR(100),\n    user_name VARCHAR(32) DEFAULT ''\n)\nDUPLICATE KEY (event_day,site_id,pv);\n-- Because the partitioning and bucketing methods are not configured, random distribution is used by default.\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Hash distribution"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"CREATE TABLE site_access2 (\n    event_day DATE,\n    site_id INT DEFAULT '10',\n    city_code SMALLINT,\n    user_name VARCHAR(32) DEFAULT '',\n    pv BIGINT SUM DEFAULT '0'\n)\nAGGREGATE KEY (event_day, site_id, city_code, user_name)\n-- Use hash bucketing as the bucketing method and must specify the bucketing key.\nDISTRIBUTED BY HASH(event_day,site_id); \n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Range+Random distribution"})," (This distribution method currently can only be used to create a Duplicate Key table.)"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"CREATE TABLE site_access3 (\n    event_day DATE,\n    site_id INT DEFAULT '10', \n    pv BIGINT DEFAULT '0' ,\n    city_code VARCHAR(100),\n    user_name VARCHAR(32) DEFAULT ''\n)\nDUPLICATE KEY(event_day,site_id,pv)\n-- Use expression partitioning as the partitioning method and configure a time function expression.\n-- You can also use range partitioning.\nPARTITION BY date_trunc('day', event_day);\n-- Because the bucketing method is not configured, random bucketing is used by default.\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Range+Hash distribution"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"CREATE TABLE site_access4 (\n    event_day DATE,\n    site_id INT DEFAULT '10',\n    city_code VARCHAR(100),\n    user_name VARCHAR(32) DEFAULT '',\n    pv BIGINT SUM DEFAULT '0'\n)\nAGGREGATE KEY(event_day, site_id, city_code, user_name)\n-- Use expression partitioning as the partitioning method and configure a time function expression.\n-- You can also use range partitioning.\nPARTITION BY date_trunc('day', event_day)\n-- Use hash bucketing as the bucketing method and must specify the bucketing key.\nDISTRIBUTED BY HASH(event_day, site_id);\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"List+Random distribution"})," (This distribution method currently can only be used to create a Duplicate Key table.)"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"CREATE TABLE t_recharge_detail1 (\n    id bigint,\n    user_id bigint,\n    recharge_money decimal(32,2), \n    city varchar(20) not null,\n    dt date not null\n)\nDUPLICATE KEY(id)\n-- Use expression partitioning as the partitioning method and specify the partitioning column.\n-- You can also use list partitioning.\nPARTITION BY (city);\n-- Because the bucketing method is not configured, random bucketing is used by default.\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"List+Hash distribution"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"CREATE TABLE t_recharge_detail2 (\n    id bigint,\n    user_id bigint,\n    recharge_money decimal(32,2), \n    city varchar(20) not null,\n    dt date not null\n)\nDUPLICATE KEY(id)\n-- Use expression partitioning as the partitioning method and specify the partitioning column.\n-- You can also use list partitionifng.\nPARTITION BY (city)\n-- Use hash bucketing as the bucketing method and must specify the bucketing key.\nDISTRIBUTED BY HASH(city,id); \n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"partitioning",children:"Partitioning"}),"\n",(0,i.jsx)(n.p,{children:"The partitioning method divides a table into multiple partitions. Partitioning primarily is used to split a table into different management units (partitions) based on the partition key. You can set a storage strategy for each partition, including the number of buckets, the strategy of storing hot and cold data, the type of storage medium, and the number of replicas. StarRocks allows you to use different types of storage mediums within a cluster. For example, you can store the latest data on solid-state drives (SSDs) to improve query performance, and historical data on SATA hard drives to reduce storage costs."}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Partitioning method"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Scenarios"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.strong,{children:"Methods to create partitions"})})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Expression partitioning (recommended)"}),(0,i.jsx)(n.td,{children:"Previously known as automatic partitioning. This partitioning method is more flexible and easy-to-use. It is suitable for most scenarios including querying and managing data based on continuous date ranges or enum values."}),(0,i.jsx)(n.td,{children:"Automatically created during data loading"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Range partitioning"}),(0,i.jsx)(n.td,{children:"The typical scenario is to store simple, ordered data that is often queried and managed based on continuous date/numeric ranges. For instance, in some special cases, historical data needs to be partitioned by month, while recent data needs to be partitioned by day."}),(0,i.jsx)(n.td,{children:"Created manually, dynamically, or in batch"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"List partitioning"}),(0,i.jsxs)(n.td,{children:["A typical scenario is to query and manage data based on enum values, and a partition needs to include data with different values for each partitioning column. For example, if you frequently query and manage data based on countries and cities, you can use this method and select ",(0,i.jsx)(n.code,{children:"city"})," as the partitioning column. So a partition can store data for multiple cities belonging to the same country."]}),(0,i.jsx)(n.td,{children:"Created manually"})]})]})]}),"\n",(0,i.jsx)(n.h5,{id:"how-to-choose-partitioning-columns-and-granularity",children:"How to choose partitioning columns and granularity"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Selecting a proper partitioning column can effectively reduce the amount of data scanned during queries. In most business systems, partitioning based on time is commonly adopted to resolve certain issues caused by the deletion of expired data and facilitate management of tiered storage of hot and cold data. In this case, you can use expression partitioning or range partitioning and specify a time column as the partitioning column. Additionally, if the data is frequently queried and managed based on enum values, you can use expression partitioning or list partitioning and specify a column including these values as the partitioning column."}),"\n",(0,i.jsxs)(n.li,{children:["When choosing the partitioning granularity, you need to consider factors data volume, query patterns, and data management granularity.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Example 1: If the monthly data volume in a table is small, partitioning by month can reduce the amount of metadata compared to partitioning by day, thereby reducing the resource consumption of metadata management and scheduling."}),"\n",(0,i.jsx)(n.li,{children:"Example 2: If the monthly data volume in a table is large and queries mostly request data of certain days, partitioning by day can effectively reduce the amount of data scanned during queries."}),"\n",(0,i.jsx)(n.li,{children:"Example 3: If the data needs to expire on a daily basis, partitioning by day is recommended."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"bucketing",children:"Bucketing"}),"\n",(0,i.jsx)(n.p,{children:"The bucketing method divides a partition into multiple buckets. Data in a bucket is referred to as a tablet."}),"\n",(0,i.jsxs)(n.p,{children:["The supported bucketing methods are ",(0,i.jsx)(n.a,{href:"#random-bucketing-since-v31",children:"random bucketing"})," (from v3.1) and ",(0,i.jsx)(n.a,{href:"#hash-bucketing",children:"hash bucketing"}),"."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Random bucketing: When creating a table or adding partitions, you do not need to set a bucketing key. Data within a partition is randomly distributed into different buckets."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Hash Bucketing: When creating a table or adding partitions, you need to specify a bucketing key. Data within the same partition is divided into buckets based on the values of the bucketing key, and rows with the same value in the bucketing key are distributed to the corresponding and unique bucket."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["The number of buckets: By default, StarRocks automatically sets the number of buckets (from v2.5.7). And you can also manually set the number of buckets. For more information, please refer to ",(0,i.jsx)(n.a,{href:"#determine-the-number-of-buckets",children:"determining the number of buckets"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"create-and-manage-partitions",children:"Create and manage partitions"}),"\n",(0,i.jsx)(n.h3,{id:"create-partitions",children:"Create partitions"}),"\n",(0,i.jsx)(n.h4,{id:"expression-partitioning-recommended",children:"Expression partitioning (recommended)"}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"NOTICE"})}),"\n",(0,i.jsxs)(n.p,{children:["Since v3.1,  StarRocks's ",(0,i.jsx)(n.a,{href:"/docusaurusv3/docs/latest/deployment/shared_data/s3",children:"shared-data mode"})," supports the time function expression and does not support the column expression."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Since v3.0, StarRocks supports ",(0,i.jsx)(n.a,{href:"/docusaurusv3/docs/latest/table_design/expression_partitioning",children:"expression partitioning"})," (previously known as automatic partitioning) which is more flexible and easy-to-use. This partitioning method is suitable for most scenarios such as querying and managing data based on continuous date ranges or enum values."]}),"\n",(0,i.jsx)(n.p,{children:"You only need to configure a partition expression (a time function expression or a column expression) at table creation, and StarRocks will automatically create partitions during data loading. You no longer need to manually create numerous partitions in advance, nor configure dynamic partition properties."}),"\n",(0,i.jsx)(n.h4,{id:"range-partitioning",children:"Range partitioning"}),"\n",(0,i.jsx)(n.p,{children:"Range partitioning is suitable for storing simple, contiguous data, such as time series data (dates or timestamps), or continuous numerical data. And you frequently query and manage data based on continuous date/numerical ranges. Also, it can be applied in some special cases where historical data needs to be partitioned by month, and recent data needs to be partitioned by day."}),"\n",(0,i.jsx)(n.p,{children:"StarRocks stores data in the corresponding partitions based on the explicit mapping of the explicitly defined range for each partition."}),"\n",(0,i.jsx)(n.h5,{id:"dynamic-partitioning",children:"Dynamic partitioning"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/docusaurusv3/docs/latest/table_design/dynamic_partitioning",children:"Dynamic partitioning"})," related properties are configured at table creation. StarRocks automatically creates new partitions in advance and removes expired partitions to ensure data freshness, which implements time-to-live (TTL) management for partitions."]}),"\n",(0,i.jsx)(n.p,{children:"Different from the automatic partition creation ability provided by the expression partitioning, dynamic partitioning can only periodically create new partitions based on the properties. If the new data does not belong to these partitions, an error is returned for the load job. However, the automatic partition creation ability provided by the expression partitioning can always create corresponding new partitions based on the loaded data."}),"\n",(0,i.jsx)(n.h5,{id:"manually-create-partitions",children:"Manually create partitions"}),"\n",(0,i.jsx)(n.p,{children:"Using a proper partition key can effectively reduce the amount of data scanned during queries. Currently, only columns of date or integer types can be selected as partitioning columns to comprise a partition key. In business scenarios, partition keys are typically selected from a data management perspective. Common partitioning columns include columns that represent dates or locations."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"CREATE TABLE site_access(\n    event_day DATE,\n    site_id INT DEFAULT '10',\n    city_code VARCHAR(100),\n    user_name VARCHAR(32) DEFAULT '',\n    pv BIGINT SUM DEFAULT '0'\n)\nAGGREGATE KEY(event_day, site_id, city_code, user_name)\nPARTITION BY RANGE(event_day)(\n    PARTITION p1 VALUES LESS THAN (\"2020-01-31\"),\n    PARTITION p2 VALUES LESS THAN (\"2020-02-29\"),\n    PARTITION p3 VALUES LESS THAN (\"2020-03-31\")\n)\nDISTRIBUTED BY HASH(site_id);\n"})}),"\n",(0,i.jsx)(n.h5,{id:"create-multiple-partitions-in-batch",children:"Create multiple partitions in batch"}),"\n",(0,i.jsxs)(n.p,{children:["Multiple partitions can be created  in batch at and after table creation. You can specify the start and end time for all the partitions created in batch in ",(0,i.jsx)(n.code,{children:"START()"})," and ",(0,i.jsx)(n.code,{children:"END()"})," and the partition increment value in ",(0,i.jsx)(n.code,{children:"EVERY()"}),". However, note that the range of partitions is right hand half open, which includes the start time but does not include the end time. The naming rule for partitions is the same as that of dynamic partitioning."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Partition a table on a date-type column (DATE and DATETIME) at table creation"})}),"\n",(0,i.jsxs)(n.p,{children:["When the partitioning column is of date type, at table creation, you can use ",(0,i.jsx)(n.code,{children:"START()"})," and ",(0,i.jsx)(n.code,{children:"END()"})," to specify the start date and end date for all the partitions created in batch, and ",(0,i.jsx)(n.code,{children:"EVERY(INTERVAL xxx)"})," to specify the incremental interval between two partitions. Currently the interval granularity supports ",(0,i.jsx)(n.code,{children:"HOUR"})," (since v3.0), ",(0,i.jsx)(n.code,{children:"DAY"}),", ",(0,i.jsx)(n.code,{children:"WEEK"}),", ",(0,i.jsx)(n.code,{children:"MONTH"}),", and ",(0,i.jsx)(n.code,{children:"YEAR"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"In the following example, the date range of all the partitions created in batch starts from 2021-01-01 and ends on 2021-01-04, with an incremental interval of one day:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:'CREATE TABLE site_access (\n  datekey DATE,\n  site_id INT,\n  city_code SMALLINT,\n  user_name VARCHAR(32),\n  pv BIGINT DEFAULT \'0\'\n)\nENGINE=olap\nDUPLICATE KEY(datekey, site_id, city_code, user_name)\nPARTITION BY RANGE (datekey) (\n  START ("2021-01-01") END ("2021-01-04") EVERY (INTERVAL 1 DAY)\n)\nDISTRIBUTED BY HASH(site_id)\nPROPERTIES ("replication_num" = "3" );\n'})}),"\n",(0,i.jsxs)(n.p,{children:["It is equivalent to using the following ",(0,i.jsx)(n.code,{children:"PARTITION BY"})," clause in the CREATE TABLE statement:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"PARTITION BY RANGE (datekey) (\nPARTITION p20210101 VALUES [('2021-01-01'), ('2021-01-02')),\nPARTITION p20210102 VALUES [('2021-01-02'), ('2021-01-03')),\nPARTITION p20210103 VALUES [('2021-01-03'), ('2021-01-04'))\n)\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Partition a table on a date-type column (DATE and DATETIME) with different date intervals at table creation"})}),"\n",(0,i.jsxs)(n.p,{children:["You can create batches of date partitions with different incremental intervals by specifying different incremental intervals in ",(0,i.jsx)(n.code,{children:"EVERY"})," for each batch of partitions (make sure that the partition ranges between different batches do not overlap). Partitions in each batch are created according to the ",(0,i.jsx)(n.code,{children:"START (xxx) END (xxx) EVERY (xxx)"})," clause. For example:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:'CREATE TABLE site_access(\n  datekey DATE,\n  site_id INT,\n  city_code SMALLINT,\n  user_name VARCHAR(32),\n  pv BIGINT DEFAULT \'0\'\n)\nENGINE=olap\nDUPLICATE KEY(datekey, site_id, city_code, user_name)\nPARTITION BY RANGE (datekey) \n(\n  START ("2019-01-01") END ("2021-01-01") EVERY (INTERVAL 1 YEAR),\n  START ("2021-01-01") END ("2021-05-01") EVERY (INTERVAL 1 MONTH),\n  START ("2021-05-01") END ("2021-05-04") EVERY (INTERVAL 1 DAY)\n)\nDISTRIBUTED BY HASH(site_id)\nPROPERTIES(\n  "replication_num" = "3"\n);\n'})}),"\n",(0,i.jsxs)(n.p,{children:["It is equivalent to using the following ",(0,i.jsx)(n.code,{children:"PARTITION BY"})," clause in the CREATE TABLE statement:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"PARTITION BY RANGE (datekey) (\nPARTITION p2019 VALUES [('2019-01-01'), ('2020-01-01')),\nPARTITION p2020 VALUES [('2020-01-01'), ('2021-01-01')),\nPARTITION p202101 VALUES [('2021-01-01'), ('2021-02-01')),\nPARTITION p202102 VALUES [('2021-02-01'), ('2021-03-01')),\nPARTITION p202103 VALUES [('2021-03-01'), ('2021-04-01')),\nPARTITION p202104 VALUES [('2021-04-01'), ('2021-05-01')),\nPARTITION p20210501 VALUES [('2021-05-01'), ('2021-05-02')),\nPARTITION p20210502 VALUES [('2021-05-02'), ('2021-05-03')),\nPARTITION p20210503 VALUES [('2021-05-03'), ('2021-05-04'))\n)\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Partition a table on an integer-type column at table creation"})}),"\n",(0,i.jsxs)(n.p,{children:["When the data type of the partitioning column is INT, you specify the range of partitions in ",(0,i.jsx)(n.code,{children:"START"})," and ",(0,i.jsx)(n.code,{children:"END"})," and define the incremental value in ",(0,i.jsx)(n.code,{children:"EVERY"}),". Example:"]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"NOTE"})}),"\n",(0,i.jsxs)(n.p,{children:["The partition column values in ",(0,i.jsx)(n.strong,{children:"START()"})," and ",(0,i.jsx)(n.strong,{children:"END()"})," need to be wrapped in double quotation marks, while the incremental value in the ",(0,i.jsx)(n.strong,{children:"EVERY()"})," does not need to be wrapped in double quotation marks."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["In the following example, the range of all the partition starts from ",(0,i.jsx)(n.code,{children:"1"})," and ends at ",(0,i.jsx)(n.code,{children:"5"}),", with a partition increment of ",(0,i.jsx)(n.code,{children:"1"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:'CREATE TABLE site_access (\n  datekey INT,\n  site_id INT,\n  city_code SMALLINT,\n  user_name VARCHAR(32),\n  pv BIGINT DEFAULT \'0\'\n)\nENGINE=olap\nDUPLICATE KEY(datekey, site_id, city_code, user_name)\nPARTITION BY RANGE (datekey) (START ("1") END ("5") EVERY (1)\n)\nDISTRIBUTED BY HASH(site_id)\nPROPERTIES ("replication_num" = "3");\n'})}),"\n",(0,i.jsxs)(n.p,{children:["It is equivalent to using the following ",(0,i.jsx)(n.code,{children:"PARTITION BY"})," clause in the CREATE TABLE statement:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"PARTITION BY RANGE (datekey) (\nPARTITION p2019 VALUES [('2019-01-01'), ('2020-01-01')),\nPARTITION p2020 VALUES [('2020-01-01'), ('2021-01-01')),\nPARTITION p202101 VALUES [('2021-01-01'), ('2021-02-01')),\nPARTITION p202102 VALUES [('2021-02-01'), ('2021-03-01')),\nPARTITION p202103 VALUES [('2021-03-01'), ('2021-04-01')),\nPARTITION p202104 VALUES [('2021-04-01'), ('2021-05-01')),\nPARTITION p20210501 VALUES [('2021-05-01'), ('2021-05-02')),\nPARTITION p20210502 VALUES [('2021-05-02'), ('2021-05-03')),\nPARTITION p20210503 VALUES [('2021-05-03'), ('2021-05-04'))\n)\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h5,{id:"create-multiple-partitions-in-batch-after-a-table-is-created",children:"Create multiple partitions in batch after a table is created"}),"\n",(0,i.jsxs)(n.p,{children:["After a table is created, you can use the ALTER TABLE statement to add partitions in. The syntax is similar to that of creating multiple partitions in batch at table creation. You need to configure ",(0,i.jsx)(n.code,{children:"START"}),", ",(0,i.jsx)(n.code,{children:"END"}),", and ",(0,i.jsx)(n.code,{children:"EVERY"})," in the ",(0,i.jsx)(n.code,{children:"ADD PARTITIONS"})," clause."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:'ALTER TABLE site_access \nADD PARTITIONS START ("2021-01-04") END ("2021-01-06") EVERY (INTERVAL 1 DAY);\n'})}),"\n",(0,i.jsx)(n.h4,{id:"list-partitioning-since-v31",children:"List partitioning (since v3.1)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/docusaurusv3/docs/latest/table_design/list_partitioning",children:"List Partitioning"})," is suitable for accelerating queries and efficiently managing data based on enum values. It is especially useful for scenarios where a partition needs to include data with different values in a partitioning column. For example, if you frequently query and manage data based on countries and cities, you can use this partitioning method and select the ",(0,i.jsx)(n.code,{children:"city"})," column as the partitioning column. In this case, one partition can contain data of various cities belonging to one country."]}),"\n",(0,i.jsx)(n.p,{children:"StarRocks stores data in the corresponding partitions based on the explicit mapping of the predefined value list for each partition."}),"\n",(0,i.jsx)(n.h3,{id:"manage--partitions",children:"Manage  partitions"}),"\n",(0,i.jsx)(n.h4,{id:"add-partitions",children:"Add partitions"}),"\n",(0,i.jsx)(n.p,{children:"For range partitioning and list partitioning, you can manually add new partitions to store new data. However for expression partitioning, because partitions are created automatically during data loading, you do not need to do so."}),"\n",(0,i.jsxs)(n.p,{children:["The following statement adds a new partition to table ",(0,i.jsx)(n.code,{children:"site_access"})," to store data for a new month:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:'ALTER TABLE site_access\nADD PARTITION p4 VALUES LESS THAN ("2020-04-30")\nDISTRIBUTED BY HASH(site_id);\n'})}),"\n",(0,i.jsx)(n.h4,{id:"delete-a-partition",children:"Delete a partition"}),"\n",(0,i.jsxs)(n.p,{children:["The following statement deletes partition ",(0,i.jsx)(n.code,{children:"p1"})," from table ",(0,i.jsx)(n.code,{children:"site_access"}),"."]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"NOTE"})}),"\n",(0,i.jsxs)(n.p,{children:["This operation does not immediately delete data in a partition. Data is retained in the Trash for a period of time (one day by default). If a partition is mistakenly deleted, you can use the ",(0,i.jsx)(n.a,{href:"/docusaurusv3/docs/latest/sql-reference/sql-statements/data-definition/RECOVER",children:"RECOVER"})," command to restore the partition and its data."]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"ALTER TABLE site_access\nDROP PARTITION p1;\n"})}),"\n",(0,i.jsx)(n.h4,{id:"restore-a-partition",children:"Restore a partition"}),"\n",(0,i.jsxs)(n.p,{children:["The following statement restores partition ",(0,i.jsx)(n.code,{children:"p1"})," and its data to table ",(0,i.jsx)(n.code,{children:"site_access"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"RECOVER PARTITION p1 FROM site_access;\n"})}),"\n",(0,i.jsx)(n.h4,{id:"view-partitions",children:"View partitions"}),"\n",(0,i.jsxs)(n.p,{children:["The following statement returns details of all partitions in table ",(0,i.jsx)(n.code,{children:"site_access"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"SHOW PARTITIONS FROM site_access;\n"})}),"\n",(0,i.jsx)(n.h2,{id:"configure-bucketing",children:"Configure bucketing"}),"\n",(0,i.jsx)(n.h3,{id:"random-bucketing-since-v31",children:"Random bucketing (since v3.1)"}),"\n",(0,i.jsx)(n.p,{children:"StarRocks distributes the data in a partition randomly across all buckets. It is suitable for scenarios with small data sizes and relatively low requirement for query performance. If you do not set a bucketing method, StarRocks uses random bucketing by default and automatically sets the number of buckets."}),"\n",(0,i.jsxs)(n.p,{children:["However, note that if you query massive amounts of data and frequently use certain columns as filter conditions, the query performance provided by random bucketing may not be optimal. In such scenarios, it is recommended to use ",(0,i.jsx)(n.a,{href:"#hash-bucketing",children:"hash bucketing"}),". When these columns are used as filter conditions for queries, only data in a small number of buckets that the query hits need to be scanned and computed, which can significantly improve query performance."]}),"\n",(0,i.jsx)(n.h4,{id:"limits",children:"Limits"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"You can only use random bucketing to create a Duplicate Key table."}),"\n",(0,i.jsxs)(n.li,{children:["You cannot specify a table bucketed randomly to belong to a ",(0,i.jsx)(n.a,{href:"/docusaurusv3/docs/latest/using_starrocks/Colocate_join",children:"Colocation Group"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/docusaurusv3/docs/latest/loading/SparkLoad",children:"Spark Load"})," cannot be used to load data into tables bucketed randomly."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["In the following CREATE TABLE example, the ",(0,i.jsx)(n.code,{children:"DISTRIBUTED BY xxx"})," statement is not used, so StarRocks uses random bucketing by default, and automatically sets the number of buckets."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"CREATE TABLE site_access1(\n    event_day DATE,\n    site_id INT DEFAULT '10', \n    pv BIGINT DEFAULT '0' ,\n    city_code VARCHAR(100),\n    user_name VARCHAR(32) DEFAULT ''\n)\nDUPLICATE KEY(event_day,site_id,pv);\n"})}),"\n",(0,i.jsx)(n.p,{children:"However, if you are familiar with StarRocks' bucketing mechanism, you can also manually set the number of buckets when creating a table with random bucketing."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"CREATE TABLE site_access2(\n    event_day DATE,\n    site_id INT DEFAULT '10', \n    pv BIGINT DEFAULT '0' ,\n    city_code VARCHAR(100),\n    user_name VARCHAR(32) DEFAULT ''\n)\nDUPLICATE KEY(event_day,site_id,pv)\nDISTRIBUTED BY RANDOM BUCKETS 8; -- manually set the number of buckets to 8\n"})}),"\n",(0,i.jsx)(n.h3,{id:"hash-bucketing",children:"Hash bucketing"}),"\n",(0,i.jsxs)(n.p,{children:["StarRocks can use hash bucketing to subdivide data in a partition into buckets based on the bucketing key and ",(0,i.jsx)(n.a,{href:"#determine-the-number-of-buckets",children:"the number of buckets"}),". In hash bucketing, a hash function takes data's bucketing key value as an input and calculates a hash value. Data is stored in the corresponding bucket based on the mapping between the hash values and buckets."]}),"\n",(0,i.jsx)(n.h4,{id:"advantages",children:"Advantages"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Improved query performance: Rows with the same bucketing key values are stored in the same bucket, reducing the amount of data scanned during queries."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Even data distribution: By selecting columns with higher cardinality (a larger number of unique values) as the bucketing key, data can be more evenly distributed across buckets."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"how-to-choose-the-bucketing-columns",children:"How to choose the bucketing columns"}),"\n",(0,i.jsx)(n.p,{children:"We recommend that you choose the column that satisfy the following two requirements as the bucketing column."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"high cardinality column such as ID"}),"\n",(0,i.jsx)(n.li,{children:"column that often used in a filter for queries"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"But if no columns satisfy both requirements, you need to determine the bucketing column according to the complexity of queries."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"If the query is complex, it is recommended that you select high cardinality columns as bucketing columns to ensure that the data is as evenly distributed as possible across all the buckets and improve the cluster resource utilization."}),"\n",(0,i.jsx)(n.li,{children:"If the query is relatively simple, it is recommended to select columns that are frequently used as filer conditions in queries as bucketing columns to improve query efficiency."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"If partition data cannot be evenly distributed across all the buckets by using one bucketing column, you can choose multiple bucketing columns. Note that it is recommended to use no more than 3 columns."}),"\n",(0,i.jsx)(n.h4,{id:"precautions",children:"Precautions"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"When a table is created, you must specify the bucketing columns"}),"."]}),"\n",(0,i.jsx)(n.li,{children:"The data types of bucketing columns must be INTEGER, DECIMAL, DATE/DATETIME, or CHAR/VARCHAR/STRING."}),"\n",(0,i.jsx)(n.li,{children:"Bucketing columns cannot be modified after they are specified."}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"examples",children:"Examples"}),"\n",(0,i.jsxs)(n.p,{children:["In the following example, the ",(0,i.jsx)(n.code,{children:"site_access"})," table is created by using ",(0,i.jsx)(n.code,{children:"site_id"})," as the bucketing column. Additionally, when data in the ",(0,i.jsx)(n.code,{children:"site_access"})," table is queried, data is often filtered by sites. Using ",(0,i.jsx)(n.code,{children:"site_id"})," as the bucketing key can prune a significant number of irrelevant buckets during queries."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"CREATE TABLE site_access(\n    event_day DATE,\n    site_id INT DEFAULT '10',\n    city_code VARCHAR(100),\n    user_name VARCHAR(32) DEFAULT '',\n    pv BIGINT SUM DEFAULT '0'\n)\nAGGREGATE KEY(event_day, site_id, city_code, user_name)\nPARTITION BY RANGE(event_day)\n(\n    PARTITION p1 VALUES LESS THAN (\"2020-01-31\"),\n    PARTITION p2 VALUES LESS THAN (\"2020-02-29\"),\n    PARTITION p3 VALUES LESS THAN (\"2020-03-31\")\n)\nDISTRIBUTED BY HASH(site_id);\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Suppose each partition of table ",(0,i.jsx)(n.code,{children:"site_access"})," has 10 buckets. In the following query, 9 out of 10 buckets are pruned, so StarRocks only needs to scan 1/10 of the data in the ",(0,i.jsx)(n.code,{children:"site_access"})," table:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"select sum(pv)\nfrom site_access\nwhere site_id = 54321;\n"})}),"\n",(0,i.jsxs)(n.p,{children:["However, if ",(0,i.jsx)(n.code,{children:"site_id"})," is unevenly distributed and a large number of queries only request data of a few sites, using only one bucketing column can result in severe data skew, causing system performance bottlenecks. In this case, you can use a combination of bucketing columns. For example, the following statement uses ",(0,i.jsx)(n.code,{children:"site_id"})," and ",(0,i.jsx)(n.code,{children:"city_code"})," as bucketing columns."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"CREATE TABLE site_access\n(\n    site_id INT DEFAULT '10',\n    city_code SMALLINT,\n    user_name VARCHAR(32) DEFAULT '',\n    pv BIGINT SUM DEFAULT '0'\n)\nAGGREGATE KEY(site_id, city_code, user_name)\nDISTRIBUTED BY HASH(site_id,city_code);\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Practically speaking, you can use one or two bucketing columns based on your business characteristics. Using one bucketing column ",(0,i.jsx)(n.code,{children:"site_id"})," is highly beneficial for short queries as it reduces data exchange between nodes, thereby enhancing the overall performance of the cluster. On the other hand, adopting two bucketing columns ",(0,i.jsx)(n.code,{children:"site_id"})," and ",(0,i.jsx)(n.code,{children:"city_code"})," is advantageous for long queries as it can leverage the overall concurrency of the distributed cluster to significantly improve performance."]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"NOTE"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Short queries involve scanning a small amount of data, and can be completed on a single node."}),"\n",(0,i.jsx)(n.li,{children:"Long queries involve scanning a large amount of data, and their performance can be significantly improved by parallel scanning across multiple nodes in a distributed cluster."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"determine-the-number-of-buckets",children:"Determine the number of buckets"}),"\n",(0,i.jsx)(n.p,{children:"Buckets reflect how data files are actually organized in StarRocks."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"How to set the number of buckets at table creation"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Method 1: automatically set the number of buckets"}),"\n",(0,i.jsx)(n.p,{children:"Since v2.5.7, StarRocks can automatically set the number of buckets based on machine resources and data volume for a partition."}),"\n",(0,i.jsx)(n.p,{children:"Example:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"CREATE TABLE site_access(\n  site_id INT DEFAULT '10',\n  city_code SMALLINT,\n  user_name VARCHAR(32) DEFAULT '',\n  pv BIGINT SUM DEFAULT '0'\n)\nAGGREGATE KEY(site_id, city_code, user_name)\nDISTRIBUTED BY HASH(site_id,city_code); -- do not need to set the number of buckets\n"})}),"\n",(0,i.jsxs)(n.p,{children:["To enable this feature, make sure that the FE dynamic parameter ",(0,i.jsx)(n.code,{children:"enable_auto_tablet_distribution"})," is set to ",(0,i.jsx)(n.code,{children:"TRUE"}),". After a table is created, you can execute ",(0,i.jsx)(n.a,{href:"/docusaurusv3/docs/latest/sql-reference/sql-statements/data-manipulation/SHOW%20CREATE%20VIEW",children:"SHOW CREATE TABLE"})," to view the bucket number automatically set by StarRocks."]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"NOTICE"})}),"\n",(0,i.jsx)(n.p,{children:"If the raw data size of a partition exceeds 100 GB, we recommend that you manually configure the number of buckets using the Method 2."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Method 2: manually set the number of buckets"}),"\n",(0,i.jsx)(n.p,{children:"Since v2.4.0, StarRocks supports using multiple threads to scan a tablet in parallel during a query, thereby reducing the dependency of scanning performance on the tablet count. We recommend that each tablet contain about 10 GB of raw data. If you intend to manually set the number of buckets, you can estimate the amount of data in each partition of a table and then decide the number of tablets."}),"\n",(0,i.jsxs)(n.p,{children:["To enable parallel scanning on tablets, make sure the ",(0,i.jsx)(n.code,{children:"enable_tablet_internal_parallel"})," parameter is set to ",(0,i.jsx)(n.code,{children:"TRUE"})," globally for the entire system (",(0,i.jsx)(n.code,{children:"SET GLOBAL enable_tablet_internal_parallel = true;"}),")."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:"CREATE TABLE site_access (\n    site_id INT DEFAULT '10',\n    city_code SMALLINT,\n    user_name VARCHAR(32) DEFAULT '',\n    pv BIGINT SUM DEFAULT '0')\nAGGREGATE KEY(site_id, city_code, user_name)\n-- Suppose the amount of raw data that you want to load into a partition is 300 GB.\n-- Because we recommend that each tablet contain 10 GB of raw data, the number of buckets can be set to 30.\nDISTRIBUTED BY HASH(site_id,city_code) BUCKETS 30;\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"How to set the number of buckets when adding a new partition"}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"NOTICE"})}),"\n",(0,i.jsx)(n.p,{children:"You cannot modify the number of buckets for an existing partition."}),"\n"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Method 1: automatically set the number of buckets (Recommended)"}),"\n",(0,i.jsxs)(n.p,{children:["Since v2.5.7, StarRocks supports automatically setting the number of buckets based on machine resources and data volume for a partition. To enable this feature, make sure that the FE dynamic parameter ",(0,i.jsx)(n.code,{children:"enable_auto_tablet_distribution"})," retains the default value ",(0,i.jsx)(n.code,{children:"TRUE"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["To disable this feature, run the ",(0,i.jsx)(n.code,{children:"ADMIN SET FRONTEND CONFIG ('enable_auto_tablet_distribution' = 'false');"})," statement. And when a new partition is added without specifying the number of buckets, the new partition inherits the the number of buckets set at the creation of the table. After a new partition is added successfully, you can execute SHOW PARTITIONS to view the number of buckets automatically set by StarRocks for the new partition."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Method 2: manually set the number of buckets"}),"\n",(0,i.jsx)(n.p,{children:"You can also manually specify the bucket count when adding a new partition. To calculate the number of buckets for a new partition, you can refer to the approach used when manually setting the number of buckets at table creation, as mentioned above."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-SQL",children:'-- Manually create partitions\nALTER TABLE <table_name> \nADD PARTITION <partition_name>\n    [DISTRIBUTED BY HASH (k1[,k2 ...]) [BUCKETS num]];\n    \n-- Dynamic partitioning\nALTER TABLE <table_name> \nSET ("dynamic_partition.buckets"="xxx");\n'})}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}const h=function(e={}){const{wrapper:n}=Object.assign({},(0,a.ah)(),e.components);return n?(0,i.jsx)(n,Object.assign({},e,{children:(0,i.jsx)(l,e)})):l(e)}},54270:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/3.3.2-1-a538e1b34e20e55ee8a4b7e523ae3f4c.png"},11151:(e,n,t)=>{t.d(n,{Zo:()=>o,ah:()=>s});var i=t(67294);const a=i.createContext({});function s(e){const n=i.useContext(a);return i.useMemo((()=>"function"==typeof e?e(n):{...n,...e}),[n,e])}const r={};function o({components:e,children:n,disableParentContext:t}){let o;return o=t?"function"==typeof e?e({}):e||r:s(e),i.createElement(a.Provider,{value:o},n)}}}]);