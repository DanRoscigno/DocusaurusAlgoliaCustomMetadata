"use strict";(self.webpackChunkstarrocks=self.webpackChunkstarrocks||[]).push([[20471],{47282:(n,e,s)=>{s.r(e),s.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>c});var r=s(85893),t=s(11151);const a={displayed_sidebar:"English"},o="Synchronize data from MySQL",i={id:"loading/Flink_cdc_load",title:"Synchronize data from MySQL",description:"This topic describes how to synchronize data from MySQL to StarRocks in seconds by using Flink CDC Connector, flink-starrocks-connector, and StarRocks Migration Tools (SMT).",source:"@site/versioned_docs/version-2.2/loading/Flink_cdc_load.md",sourceDirName:"loading",slug:"/loading/Flink_cdc_load",permalink:"/docs/2.2/loading/Flink_cdc_load",draft:!1,unlisted:!1,editUrl:"https://github.com/StarRocks/starrocks/edit/main/docs/loading/Flink_cdc_load.md",tags:[],version:"2.2",frontMatter:{displayed_sidebar:"English"},sidebar:"English",previous:{title:"Continuously load data from Apache Flink\xae",permalink:"/docs/2.2/loading/Flink-connector-starrocks"},next:{title:"Insert Into Loading",permalink:"/docs/2.2/loading/InsertInto"}},l={},c=[{value:"Before you begin",id:"before-you-begin",level:2},{value:"How it works",id:"how-it-works",level:2},{value:"Procedure",id:"procedure",level:2},{value:"Usage note",id:"usage-note",level:2}];function d(n){const e=Object.assign({h1:"h1",p:"p",h2:"h2",ul:"ul",li:"li",strong:"strong",pre:"pre",code:"code",a:"a",img:"img",ol:"ol",blockquote:"blockquote"},(0,t.ah)(),n.components);return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.h1,{id:"synchronize-data-from-mysql",children:"Synchronize data from MySQL"}),"\n",(0,r.jsx)(e.p,{children:"This topic describes how to synchronize data from MySQL to StarRocks in seconds by using Flink CDC Connector, flink-starrocks-connector, and StarRocks Migration Tools (SMT)."}),"\n",(0,r.jsx)(e.h2,{id:"before-you-begin",children:"Before you begin"}),"\n",(0,r.jsx)(e.p,{children:"Before you start data synchronization, enable the binary logging in MySQL and download the following software packages:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Modify the ",(0,r.jsx)(e.strong,{children:"/etc/my.cnf"})," file to enable binary logging in MySQL and then restart MySQL Server (mysqld). You can execute the SHOW VARIABLES LIKE 'log_bin' statement to check whether binary logging is enabled."]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-Plain_Text",children:"#Enable binlog\n\nlog-bin=/var/lib/mysql/mysql-bin\n\n\n\n#log_bin=ON\n\n##Base name for binlog files\n\n#log_bin_basename=/var/lib/mysql/mysql-bin\n\n##Index file to manage all binlog files\n\n#log_bin_index=/var/lib/mysql/mysql-bin.index\n\n#Configure serverid\n\nserver-id=1\n\nbinlog_format = row\n"})}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.a,{href:"https://flink.apache.org/downloads.html",children:"Apache Flink"}),". Only Apache Flink 1.1 and later are supported. We recommend that you download Apache Flink 1.13."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.a,{href:"https://github.com/ververica/flink-cdc-connectors/releases",children:"Flink CDC Connector"}),". To synchronize data from MySQL to StarRocks, download Flink-MySQL-CDC that is used with the version of Apache Flink you downloaded."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.a,{href:"https://github.com/StarRocks/flink-connector-starrocks",children:"Flink-connector-starrocks"}),". Apache Flink 1.13 uses a different version of flink-connector-starrocks than Apache Flink 1.11 and Apache Flink 1.12."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.a,{href:"http://starrocks-public.oss-cn-zhangjiakou.aliyuncs.com/flink/smt.tar.gz",children:"SMT"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"how-it-works",children:"How it works"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.img,{alt:"MySQL \u540c\u6b65",src:s(21839).Z+"",width:"1354",height:"326"})}),"\n",(0,r.jsx)(e.p,{children:"The preceding figure shows the workflow of data synchronization:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"SMT generates the statements that are used to create the source table and the sink table based on the cluster information and the table schema of MySQL and StarRocks."}),"\n",(0,r.jsx)(e.li,{children:"Flink CDC Connector acquires binary log data from MySQL."}),"\n",(0,r.jsx)(e.li,{children:"Flink-connector-starrocks loads the data into StarRocks."}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"procedure",children:"Procedure"}),"\n",(0,r.jsx)(e.p,{children:"Perform the following steps to synchronize data:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Duplicate flink-sql-connector-mysql-cdc-xxx.jar and flink-connector-starrocks-xxx.jar to the ",(0,r.jsx)(e.code,{children:"flink-xxx/lib/"})," directory."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Decompress SMT and modify the configuration file of SMT:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.code,{children:"DB"}),": modify the value of this parameter to the connection information of MySQL."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.code,{children:"be_num"}),": the number of nodes in your StarRocks cluster. This parameter helps you to set the number of buckets more reasonably."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.code,{children:"[table-rule.1]"}),": the rule based on which you want to match data. You can match the databases and tables by using regular expressions, thus generate the SQL statements that are used to create tables. You can configure multiple rules."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.code,{children:"flink.starrocks.*"}),": the configuration information of your StarRocks cluster. For more information, see ",(0,r.jsx)(e.a,{href:"/docs/2.2/loading/Flink-connector-starrocks",children:"Load data by using flink-connector-starrocks"}),"."]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-Plain_Text",children:"[db]\n\nhost = 192.168.1.1\n\nport = 3306\n\nuser = root\n\npassword =  \n\n\n\n[other]\n\n# number of backends in StarRocks\n\nbe_num = 3\n\n# `decimal_v3` is supported since StarRocks-1.18.1\n\nuse_decimal_v3 = false\n\n# file to save the converted DDL SQL\n\noutput_dir = ./result\n\n\n\n\n\n[table-rule.1]\n\n# pattern to match databases for setting properties\n\ndatabase = ^console_19321.*$\n\n# pattern to match tables for setting properties\n\ntable = ^.*$\n\n\n\n############################################\n\n### flink sink configurations\n\n### DO NOT set `connector`, `table-name`, `database-name`, they are auto-generated\n\n############################################\n\nflink.starrocks.jdbc-url=jdbc:mysql://192.168.1.1:9030\n\nflink.starrocks.load-url= 192.168.1.1:8030\n\nflink.starrocks.username=root\n\nflink.starrocks.password=\n\nflink.starrocks.sink.properties.column_separator=\\x01\n\nflink.starrocks.sink.properties.row_delimiter=\\x02\n\nflink.starrocks.sink.buffer-flush.interval-ms=15000\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Use the statements that are generated by SMT to create StarRocks tables and Apache Flink tables. All generated statements are saved in the ",(0,r.jsx)(e.strong,{children:"result"})," directory."]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-SQL",children:"$./starrocks-migrate-tool\n\n$ls result\n\nflink-create.1.sql    smt.tar.gz              starrocks-create.all.sql\n\nflink-create.all.sql  starrocks-create.1.sql\n"})}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Create a StarRocks table."}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-SQL",children:"Mysql -hxx.xx.xx.x -P9030 -uroot -p < starrocks-create.1.sql\n"})}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Create an Apache Flink table and then start a data synchronization task. Once the synchronization task begins, all existing data and subsequent modifications to data are synchronized to StarRocks."}),"\n",(0,r.jsxs)(e.blockquote,{children:["\n",(0,r.jsxs)(e.p,{children:["Note: When you perform this step, ensure that the Apache Flink cluster has been started. If not, use the ",(0,r.jsx)(e.code,{children:"flink/bin/start-cluster.sh"})," to start it."]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-SQL",children:"bin/sql-client.sh -f flink-create.1.sql\n"})}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Check the status of the synchronization task. If an error occurs, you can view the task log for the error message and then adjust the memory and the slot in the system configuration of ",(0,r.jsx)(e.strong,{children:"conf/flink-conf.yaml"}),". For more information, see ",(0,r.jsx)(e.a,{href:"https://nightlies.apache.org/flink/flink-docs-master/zh/docs/deployment/config/",children:"Configuration"})," in Apache Flink."]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-SQL",children:"bin/flink list \n"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"usage-note",children:"Usage note"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"If you configure multiple match rules, you need to match the database, table, and flink-connector-starrocks for each match rule."}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-Plain_Text",children:"[table-rule.1]\n\n# pattern to match databases for setting properties\n\ndatabase = ^console_19321.*$\n\n# pattern to match tables for setting properties\n\ntable = ^.*$\n\n\n\n############################################\n\n### flink sink configurations\n\n### DO NOT set `connector`, `table-name`, `database-name`, they are auto-generated\n\n############################################\n\nflink.starrocks.jdbc-url=jdbc:mysql://192.168.1.1:9030\n\nflink.starrocks.load-url= 192.168.1.1:8030\n\nflink.starrocks.username=root\n\nflink.starrocks.password=\n\nflink.starrocks.sink.properties.column_separator=\\x01\n\nflink.starrocks.sink.properties.row_delimiter=\\x02\n\nflink.starrocks.sink.buffer-flush.interval-ms=15000\n\n\n\n[table-rule.2]\n\n# pattern to match databases for setting properties\n\ndatabase = ^database2.*$\n\n# pattern to match tables for setting properties\n\ntable = ^.*$\n\n\n\n############################################\n\n### flink sink configurations\n\n### DO NOT set `connector`, `table-name`, `database-name`, they are auto-generated\n\n############################################\n\nflink.starrocks.jdbc-url=jdbc:mysql://192.168.1.1:9030\n\nflink.starrocks.load-url= 192.168.1.1:8030\n\nflink.starrocks.username=root\n\nflink.starrocks.password=\n\n# If you cannot select a suitable separator for the loaded data, you can use JSON format by replacing flink.starrocks.sink.properties.column_separator and flink.starrocks.sink.properties.row_delimiter with the following parameters. Note: By doing so, the import performance will be impacted. \n\nflink.starrocks.sink.properties.strip_outer_array=true\n\nflink.starrocks.sink.properties.format=json\n"})}),"\n",(0,r.jsxs)(e.blockquote,{children:["\n",(0,r.jsxs)(e.p,{children:["Note: If you want to configure more parameters, such as the frequency to load data, see ",(0,r.jsx)(e.a,{href:"/docs/2.2/loading/Flink-connector-starrocks",children:"Load data by using Flink-connector-starrocks"})," for more information about ",(0,r.jsx)(e.code,{children:"sink"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["You can configure an individual match rule for a sharded large table. For example, you have two databases, ",(0,r.jsx)(e.code,{children:"edu_db_1"})," and ",(0,r.jsx)(e.code,{children:"edu_db_2"}),", each database contains two tables, ",(0,r.jsx)(e.code,{children:"course_1"})," and ",(0,r.jsx)(e.code,{children:"course_2"}),". In addition, all these tables use the same schema. You can use the following configurations to load the preceding four tables into StarRocks:"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-Plain_Text",children:"[table-rule.3]\n\n# pattern to match databases for setting properties\n\ndatabase = ^edu_db_[0-9]*$\n\n# pattern to match tables for setting properties\n\ntable = ^course_[0-9]*$\n\n\n\n############################################\n\n### flink sink configurations\n\n### DO NOT set `connector`, `table-name`, `database-name`, they are auto-generated\n\n############################################\n\nflink.starrocks.jdbc-url=jdbc:mysql://192.168.1.1:9030\n\nflink.starrocks.load-url= 192.168.1.1:8030\n\nflink.starrocks.username=root\n\nflink.starrocks.password=\n\nflink.starrocks.sink.properties.column_separator=\\x01\n\nflink.starrocks.sink.properties.row_delimiter=\\x02\n\nflink.starrocks.sink.buffer-flush.interval-ms=5000\n"})}),"\n",(0,r.jsxs)(e.p,{children:["After the tables are loaded, StarRocks generates a new table named ",(0,r.jsx)(e.code,{children:"course_auto_shared"}),". You can modify the name of the table in the configuration file that is automatically generated."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["If you want to create tables and synchronize data by using the command line of SQL Client, you need to escape the ",(0,r.jsx)(e.code,{children:"\\"})," (backslash)."]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-SQL",children:"'sink.properties.column_separator' = '\\\\x01'\n\n'sink.properties.row_delimiter' = '\\\\x02'  \n"})}),"\n"]}),"\n"]})]})}const h=function(n={}){const{wrapper:e}=Object.assign({},(0,t.ah)(),n.components);return e?(0,r.jsx)(e,Object.assign({},n,{children:(0,r.jsx)(d,n)})):d(n)}},21839:(n,e,s)=>{s.d(e,{Z:()=>r});const r=s.p+"assets/images/4.9.2-bde39f3aa7c56cfb1c29cdeb7de03e0c.png"},11151:(n,e,s)=>{s.d(e,{Zo:()=>i,ah:()=>a});var r=s(67294);const t=r.createContext({});function a(n){const e=r.useContext(t);return r.useMemo((()=>"function"==typeof n?n(e):{...e,...n}),[e,n])}const o={};function i({components:n,children:e,disableParentContext:s}){let i;return i=s?"function"==typeof n?n({}):n||o:a(n),r.createElement(t.Provider,{value:i},e)}}}]);