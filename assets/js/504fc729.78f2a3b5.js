"use strict";(self.webpackChunkstarrocks=self.webpackChunkstarrocks||[]).push([[43092],{17624:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>a,metadata:()=>c,toc:()=>d});var s=n(85893),r=n(11151);const a={displayed_sidebar:"English"},i="External tables",c={id:"data_source/External_table",title:"External tables",description:"StarRocks supports access to other data sources by using external tables. External tables are created based on data tables that are stored in other data sources. StarRocks only stores the metadata of the data tables. You can use external tables to directly query data in other data sources. StarRocks supports the following data sources: MySQL, Elasticsearch, Hive, StarRocks, Apache Iceberg, and Apache Hudi. Currently, you can only write data from another StarRocks cluster into the current StarRocks cluster. You cannot read data from it. For data sources other than StarRocks, you can only read data from these data sources.",source:"@site/versioned_docs/version-2.2/data_source/External_table.md",sourceDirName:"data_source",slug:"/data_source/External_table",permalink:"/docs/2.2/data_source/External_table",draft:!1,unlisted:!1,editUrl:"https://github.com/StarRocks/starrocks/edit/main/docs/data_source/External_table.md",tags:[],version:"2.2",frontMatter:{displayed_sidebar:"English"},sidebar:"English",previous:{title:"TPC-H Benchmarking",permalink:"/docs/2.2/benchmarking/TPC-H_Benchmarking"},next:{title:"Deployment",permalink:"/docs/2.2/faq/Deploy_faq"}},l={},d=[{value:"MySQL external table",id:"mysql-external-table",level:2},{value:"Elasticsearch external table",id:"elasticsearch-external-table",level:2},{value:"Example of creating an Elasticsearch external table",id:"example-of-creating-an-elasticsearch-external-table",level:3},{value:"Predicate pushdown",id:"predicate-pushdown",level:3},{value:"Example",id:"example",level:3},{value:"Note",id:"note",level:3},{value:"Hive external table",id:"hive-external-table",level:2},{value:"Create a Hive resource",id:"create-a-hive-resource",level:3},{value:"Create a database",id:"create-a-database",level:3},{value:"Create a Hive external table",id:"create-a-hive-external-table",level:3},{value:"Use a Hive external table",id:"use-a-hive-external-table",level:3},{value:"Configuration",id:"configuration",level:3},{value:"Metadata caching strategy",id:"metadata-caching-strategy",level:3},{value:"StarRocks external table",id:"starrocks-external-table",level:2},{value:"Apache Iceberg external table",id:"apache-iceberg-external-table",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Precautions",id:"precautions",level:3},{value:"Procedure",id:"procedure",level:3},{value:"Step 1: Create and manage Iceberg resources",id:"step-1-create-and-manage-iceberg-resources",level:4},{value:"Create a resource whose catalog type is <code>HIVE</code>",id:"create-a-resource-whose-catalog-type-is-hive",level:5},{value:"Create a resource whose catalog type is <code>CUSTOM</code>",id:"create-a-resource-whose-catalog-type-is-custom",level:5},{value:"View Iceberg resources",id:"view-iceberg-resources",level:5},{value:"Drop an Iceberg resource",id:"drop-an-iceberg-resource",level:5},{value:"Step 2: Create an Iceberg database",id:"step-2-create-an-iceberg-database",level:4},{value:"Step 3: Create an Iceberg external table",id:"step-3-create-an-iceberg-external-table",level:4},{value:"Step 4: Query Iceberg data",id:"step-4-query-iceberg-data",level:4},{value:"Hudi external table",id:"hudi-external-table",level:2},{value:"Before you begin",id:"before-you-begin",level:3},{value:"Precautions",id:"precautions-1",level:3},{value:"Procedure",id:"procedure-1",level:3},{value:"Step 1: Create and manage Hudi resources",id:"step-1-create-and-manage-hudi-resources",level:4},{value:"Create a Hudi resource",id:"create-a-hudi-resource",level:5},{value:"View Hudi resources",id:"view-hudi-resources",level:5},{value:"Delete a Hudi resource",id:"delete-a-hudi-resource",level:5},{value:"Step 2: Create Hudi databases",id:"step-2-create-hudi-databases",level:4},{value:"Step 3: Create Hudi external tables",id:"step-3-create-hudi-external-tables",level:4},{value:"Step 4: Query data from a Hudi external table",id:"step-4-query-data-from-a-hudi-external-table",level:4}];function o(e){const t=Object.assign({h1:"h1",p:"p",strong:"strong",h2:"h2",pre:"pre",code:"code",ul:"ul",li:"li",h3:"h3",table:"table",thead:"thead",tr:"tr",th:"th",tbody:"tbody",td:"td",blockquote:"blockquote",ol:"ol",a:"a",h4:"h4",h5:"h5"},(0,r.ah)(),e.components);return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.h1,{id:"external-tables",children:"External tables"}),"\n",(0,s.jsxs)(t.p,{children:["StarRocks supports access to other data sources by using external tables. External tables are created based on data tables that are stored in other data sources. StarRocks only stores the metadata of the data tables. You can use external tables to directly query data in other data sources. StarRocks supports the following data sources: MySQL, Elasticsearch, Hive, StarRocks, Apache Iceberg, and Apache Hudi. ",(0,s.jsx)(t.strong,{children:"Currently, you can only write data from another StarRocks cluster into the current StarRocks cluster. You cannot read data from it. For data sources other than StarRocks, you can only read data from these data sources."})]}),"\n",(0,s.jsx)(t.h2,{id:"mysql-external-table",children:"MySQL external table"}),"\n",(0,s.jsx)(t.p,{children:"In the star schema, data is generally divided into dimension tables and fact tables. Dimension tables have less data but involve UPDATE operations. Currently, StarRocks does not support direct UPDATE operations (update can be implemented by using the unique key model). In some scenarios, you can store dimension tables in MySQL for direct data read."}),"\n",(0,s.jsx)(t.p,{children:"To query MySQL data, you must create an external table in StarRocks and map it to the table in your MySQL database. You need to specify the MySQL connection information when creating the table."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sql",children:'CREATE EXTERNAL TABLE mysql_external_table\n(\n    k1 DATE,\n    k2 INT,\n    k3 SMALLINT,\n    k4 VARCHAR(2048),\n    k5 DATETIME\n)\nENGINE=mysql\nPROPERTIES\n(\n    "host" = "127.0.0.1",\n    "port" = "3306",\n    "user" = "mysql_user",\n    "password" = "mysql_passwd",\n    "database" = "mysql_db_test",\n    "table" = "mysql_table_test"\n);\n'})}),"\n",(0,s.jsx)(t.p,{children:"Parameters:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"host"}),": the connection address of the MySQL database"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"port"}),": the port number of the MySQL database"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"user"}),": the username to log in to MySQL"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"password"}),": the password to log in to MySQL"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"database"}),": the name of the MySQL database"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"table"}),": the name of the table in the MySQL database"]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"elasticsearch-external-table",children:"Elasticsearch external table"}),"\n",(0,s.jsx)(t.p,{children:"StarRocks and Elasticsearch are two popular analytics systems. StarRocks is performant in large-scale distributed computing. Elasticsearch is ideal for full-text search. StarRocks combined with Elasticsearch can deliver a more complete OLAP solution."}),"\n",(0,s.jsx)(t.h3,{id:"example-of-creating-an-elasticsearch-external-table",children:"Example of creating an Elasticsearch external table"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sql",children:'CREATE EXTERNAL TABLE elastic_search_external_table\n(\n    k1 DATE,\n    k2 INT,\n    k3 SMALLINT,\n    k4 VARCHAR(2048),\n    k5 DATETIME\n)\nENGINE=ELASTICSEARCH\nPARTITION BY RANGE(k1)\n()\nPROPERTIES (\n    "hosts" = "http://192.168.0.1:8200,http://192.168.0.2:8200",\n    "user" = "root",\n    "password" = "root",\n    "index" = "tindex",\n    "type" = "doc"\n);\n'})}),"\n",(0,s.jsx)(t.p,{children:"Parameters"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{align:"center",children:"Parameter"}),(0,s.jsx)(t.th,{align:"center",children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{align:"center",children:"host"}),(0,s.jsx)(t.td,{align:"center",children:"The connection address of the Elasticsearch cluster. You can specify one or more addresses. StarRocks can parse the Elasticsearch version and index shard allocation from this address."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{align:"center",children:"user"}),(0,s.jsxs)(t.td,{align:"center",children:["The username of the Elasticsearch cluster with ",(0,s.jsx)(t.strong,{children:"basic authentication"})," enabled. Make sure you have the access to ",(0,s.jsx)(t.code,{children:"/*cluster/state/*nodes/http"})," and the index."]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{align:"center",children:"password"}),(0,s.jsx)(t.td,{align:"center",children:"The password of the Elasticsearch cluster."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{align:"center",children:"index"}),(0,s.jsx)(t.td,{align:"center",children:"The name of the Elasticsearch index that corresponds to the table in StarRocks. It can be an alias."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{align:"center",children:"type"}),(0,s.jsx)(t.td,{align:"center",children:"he type of the index. Default value: doc."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{align:"center",children:"transport"}),(0,s.jsx)(t.td,{align:"center",children:"This parameter is reserved. Default value: http."})]})]})]}),"\n",(0,s.jsx)(t.h3,{id:"predicate-pushdown",children:"Predicate pushdown"}),"\n",(0,s.jsx)(t.p,{children:"StarRocks supports predicate pushdown. Filters can be pushed down to Elasticsearch for execution, which improves query performance. The following table lists the operators that support predicate pushdown."}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{align:"center",children:"SQL syntax"}),(0,s.jsx)(t.th,{align:"center",children:"ES syntax"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{align:"center",children:(0,s.jsx)(t.code,{children:"="})}),(0,s.jsx)(t.td,{align:"center",children:"term query"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{align:"center",children:(0,s.jsx)(t.code,{children:"in"})}),(0,s.jsx)(t.td,{align:"center",children:"terms query"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{align:"center",children:(0,s.jsx)(t.code,{children:"\\>=,  <=, >, <"})}),(0,s.jsx)(t.td,{align:"center",children:"range"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{align:"center",children:(0,s.jsx)(t.code,{children:"and"})}),(0,s.jsx)(t.td,{align:"center",children:"bool.filter"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{align:"center",children:(0,s.jsx)(t.code,{children:"or"})}),(0,s.jsx)(t.td,{align:"center",children:"bool.should"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{align:"center",children:(0,s.jsx)(t.code,{children:"not"})}),(0,s.jsx)(t.td,{align:"center",children:"bool.must_not"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{align:"center",children:(0,s.jsx)(t.code,{children:"not in"})}),(0,s.jsx)(t.td,{align:"center",children:"bool.must_not + terms"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{align:"center",children:(0,s.jsx)(t.code,{children:"esquery"})}),(0,s.jsx)(t.td,{align:"center",children:"ES Query DSL"})]})]})]}),"\n",(0,s.jsx)(t.h3,{id:"example",children:"Example"}),"\n",(0,s.jsxs)(t.p,{children:["The ",(0,s.jsx)(t.strong,{children:"esquery function"})," is used to push down queries ",(0,s.jsx)(t.strong,{children:"that cannot be expressed in SQL"})," (such as match and geoshape) to Elasticsearch for filtering. The first parameter in the esquery function is used to associate an index. The second parameter is a JSON expression of basic Query DSL, which is enclosed in brackets ",". ",(0,s.jsx)(t.strong,{children:"The JSON expression must have but only one root key"}),", such as match, geo_shape, or bool."]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"match query"}),"\n"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sql",children:'select * from es_table where esquery(k4, \'{\n    "match": {\n       "k4": "StarRocks on elasticsearch"\n    }\n}\');\n'})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"geo-related query"}),"\n"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sql",children:'select * from es_table where esquery(k4, \'{\n  "geo_shape": {\n     "location": {\n        "shape": {\n           "type": "envelope",\n           "coordinates": [\n              [\n                 13,\n                 53\n              ],\n              [\n                 14,\n                 52\n              ]\n           ]\n        },\n        "relation": "within"\n     }\n  }\n}\');\n'})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"bool query"}),"\n"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sql",children:'select * from es_table where esquery(k4, \' {\n     "bool": {\n        "must": [\n           {\n              "terms": {\n                 "k1": [\n                    11,\n                    12\n                 ]\n              }\n           },\n           {\n              "terms": {\n                 "k2": [\n                    100\n                 ]\n              }\n           }\n        ]\n     }\n  }\');\n'})}),"\n",(0,s.jsx)(t.h3,{id:"note",children:"Note"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["Elasticsearch earlier than 5.x scans data in a different way than that later than 5.x. Currently, ",(0,s.jsx)(t.strong,{children:"only versions later than 5.x"})," are supported."]}),"\n",(0,s.jsx)(t.li,{children:"Elasticsearch clusters with HTTP basic authentication enabled are supported."}),"\n",(0,s.jsx)(t.li,{children:"Querying data from StarRocks may not be as fast as directly querying data from Elasticsearch, such as count-related queries. The reason is that Elasticsearch directly reads the metadata of target documents without the need to filter the real data, which accelerates the count query."}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"hive-external-table",children:"Hive external table"}),"\n",(0,s.jsx)(t.h3,{id:"create-a-hive-resource",children:"Create a Hive resource"}),"\n",(0,s.jsx)(t.p,{children:"A Hive resource corresponds to a Hive cluster. You must configure the Hive cluster used by StarRocks, such as the Hive metastore address. You must specify the Hive resource that is used by the Hive external table."}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Create a Hive resource named hive0."}),"\n"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sql",children:'CREATE EXTERNAL RESOURCE "hive0"\nPROPERTIES (\n  "type" = "hive",\n  "hive.metastore.uris" = "thrift://10.10.44.98:9083"\n);\n'})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"View the resources created in StarRocks."}),"\n"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sql",children:"SHOW RESOURCES;\n"})}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["Delete the resource named ",(0,s.jsx)(t.code,{children:"hive0"}),"."]}),"\n"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sql",children:'DROP RESOURCE "hive0";\n'})}),"\n",(0,s.jsx)(t.h3,{id:"create-a-database",children:"Create a database"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sql",children:"CREATE DATABASE hive_test;\nUSE hive_test;\n"})}),"\n",(0,s.jsx)(t.h3,{id:"create-a-hive-external-table",children:"Create a Hive external table"}),"\n",(0,s.jsx)(t.p,{children:"Syntax"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sql",children:'CREATE EXTERNAL TABLE table_name (\n  col_name col_type [NULL | NOT NULL] [COMMENT "comment"]\n) ENGINE=HIVE\nPROPERTIES (\n  "key" = "value"\n);\n'})}),"\n",(0,s.jsxs)(t.p,{children:["Example: Create the external table ",(0,s.jsx)(t.code,{children:"profile_parquet_p7"})," under the ",(0,s.jsx)(t.code,{children:"rawdata"})," database in the Hive cluster corresponding to the ",(0,s.jsx)(t.code,{children:"hive0"})," resource."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sql",children:'CREATE EXTERNAL TABLE `profile_wos_p7` (\n  `id` bigint NULL,\n  `first_id` varchar(200) NULL,\n  `second_id` varchar(200) NULL,\n  `p__device_id_list` varchar(200) NULL,\n  `p__is_deleted` bigint NULL,\n  `p_channel` varchar(200) NULL,\n  `p_platform` varchar(200) NULL,\n  `p_source` varchar(200) NULL,\n  `p__city` varchar(200) NULL,\n  `p__province` varchar(200) NULL,\n  `p__update_time` bigint NULL,\n  `p__first_visit_time` bigint NULL,\n  `p__last_seen_time` bigint NULL\n) ENGINE=HIVE\nPROPERTIES (\n  "resource" = "hive0",\n  "database" = "rawdata",\n  "table" = "profile_parquet_p7"\n);\n'})}),"\n",(0,s.jsx)(t.p,{children:"Description:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"Columns in the external table"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"The column names must be the same as column names in the Hive table."}),"\n",(0,s.jsxs)(t.li,{children:["The column order ",(0,s.jsx)(t.strong,{children:"does not need to be"})," the same as column order in the Hive table."]}),"\n",(0,s.jsxs)(t.li,{children:["You can select only ",(0,s.jsx)(t.strong,{children:"some of the columns in the Hive table"}),", but you must select all the ",(0,s.jsx)(t.strong,{children:"partition key columns"}),"."]}),"\n",(0,s.jsxs)(t.li,{children:["Partition key columns of an external table do not need to be specified by using ",(0,s.jsx)(t.code,{children:"partition by"}),". They must be defined in the same description list as other columns. You do not need to specify partition information. StarRocks will automatically synchronize this information from the Hive table."]}),"\n",(0,s.jsxs)(t.li,{children:["Set ",(0,s.jsx)(t.code,{children:"ENGINE"})," to HIVE."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"PROPERTIES:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"hive.resource"}),": the Hive resource that is used."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"database"}),": the Hive database."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"table"}),": the table in Hive. ",(0,s.jsx)(t.strong,{children:"view"})," is not supported."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"The following table describes the column data type mapping between Hive and StarRocks."}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Column type of Hive"}),(0,s.jsx)(t.th,{children:"Column type of StarRocks"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"INT/INTEGER"}),(0,s.jsx)(t.td,{children:"INT"}),(0,s.jsx)(t.td,{})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"BIGINT"}),(0,s.jsx)(t.td,{children:"BIGINT"}),(0,s.jsx)(t.td,{})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"TIMESTAMP"}),(0,s.jsx)(t.td,{children:"DATETIME"}),(0,s.jsx)(t.td,{children:"Precision and time zone information will be lost when you convert TIMESTAMP data into DATETIME data. You need to convert TIMESTAMP data into DATETIME data that does not have the time zone offset based on the time zone in sessionVariable."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"STRING"}),(0,s.jsx)(t.td,{children:"VARCHAR"}),(0,s.jsx)(t.td,{})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"VARCHAR"}),(0,s.jsx)(t.td,{children:"VARCHAR"}),(0,s.jsx)(t.td,{})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"CHAR"}),(0,s.jsx)(t.td,{children:"CHAR"}),(0,s.jsx)(t.td,{})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"DOUBLE"}),(0,s.jsx)(t.td,{children:"DOUBLE"}),(0,s.jsx)(t.td,{})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"FLOATE"}),(0,s.jsx)(t.td,{children:"FLOAT"}),(0,s.jsx)(t.td,{})]})]})]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"Note:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["Hive table schema changes ",(0,s.jsx)(t.strong,{children:"will not be automatically synchronized to the external table"}),". You must create another Hive external table in StarRocks."]}),"\n",(0,s.jsx)(t.li,{children:"Currently, the supported Hive storage formats are Parquet, ORC, and CSV."}),"\n"]}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:"If the storage format is CSV, quotation marks cannot be used as escape characters."}),"\n"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"The SNAPPY and LZ4 compression formats are supported."}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"use-a-hive-external-table",children:"Use a Hive external table"}),"\n",(0,s.jsxs)(t.p,{children:["Query the total number of rows of ",(0,s.jsx)(t.code,{children:"profile_wos_p7"}),"."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sql",children:"select count(*) from profile_wos_p7;\n"})}),"\n",(0,s.jsx)(t.h3,{id:"configuration",children:"Configuration"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:["The path of the FE configuration file is ",(0,s.jsx)(t.code,{children:"fe/conf"}),", to which the configuration file can be added if you need to customize the Hadoop cluster. For example: HDFS cluster uses a highly available nameservice, you need to put ",(0,s.jsx)(t.code,{children:"hdfs-site.xml"})," under ",(0,s.jsx)(t.code,{children:"fe/conf"}),".  If HDFS is configured with viewfs, you need to put the ",(0,s.jsx)(t.code,{children:"core-site.xml"})," under ",(0,s.jsx)(t.code,{children:"fe/conf"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:["The path of the BE configuration file is ",(0,s.jsx)(t.code,{children:"be/conf"}),", to which configuration file can be added if you need to customize the Hadoop cluster. For example, HDFS cluster using a highly available nameservice, you need to put ",(0,s.jsx)(t.code,{children:"hdfs-site.xml"})," under ",(0,s.jsx)(t.code,{children:"be/conf"}),". If HDFS is configured with viewfs, you need to put ",(0,s.jsx)(t.code,{children:"core-site.xml"})," under ",(0,s.jsx)(t.code,{children:"be/conf"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"The machine where BE is located need to configure JAVA_HOME as a jdk environment rather than a jre environment"}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"kerbero supports:"}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{children:["To log in with ",(0,s.jsx)(t.code,{children:"kinit -kt keytab_path principal"})," to all FE/BE machines, you need to have access to Hive and HDFS. The kinit command login is only good for a period of time and needs to be put into crontab to be executed regularly."]}),"\n",(0,s.jsxs)(t.li,{children:["Put ",(0,s.jsx)(t.code,{children:"hive-site.xml/core-site.xml/hdfs-site.xml"})," under ",(0,s.jsx)(t.code,{children:"fe/conf"}),", and put ",(0,s.jsx)(t.code,{children:"core-site.xml/hdfs-site.xml"})," under ",(0,s.jsx)(t.code,{children:"be/conf"}),"."]}),"\n",(0,s.jsxs)(t.li,{children:["Add ",(0,s.jsx)(t.strong,{children:"Djava.security.krb5.conf:/etc/krb5.conf"})," to the ",(0,s.jsx)(t.strong,{children:"JAVA_OPTS/JAVA_OPTS_FOR_JDK_9"})," option of the ",(0,s.jsx)(t.strong,{children:"fe/conf/fe.conf"})," file.  ",(0,s.jsx)(t.strong,{children:"/etc/krb5.conf"})," is the path of the ",(0,s.jsx)(t.strong,{children:"krb5.conf"})," file. You can adjust the path based on your operating system."]}),"\n",(0,s.jsxs)(t.li,{children:["When you add a Hive resource, you must pass in a domain name to ",(0,s.jsx)(t.code,{children:"hive.metastore.uris"}),". In addition, you must add the mapping between Hive/HDFS domain names and IP addresses in the ",(0,s.jsx)(t.strong,{children:"/etc/hosts"})," file*.*"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:["Configure support for AWS S3: Add the following configuration to ",(0,s.jsx)(t.code,{children:"fe/conf/core-site.xml"})," and ",(0,s.jsx)(t.code,{children:"be/conf/core-site.xml"}),"."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-XML",children:"<configuration>\n   <property>\n      <name>fs.s3a.access.key</name>\n      <value>******</value>\n   </property>\n   <property>\n      <name>fs.s3a.secret.key</name>\n      <value>******</value>\n   </property>\n   <property>\n      <name>fs.s3a.endpoint</name>\n      <value>s3.us-west-2.amazonaws.com</value>\n   </property>\n   <property>\n   <name>fs.s3a.connection.maximum</name>\n   <value>500</value>\n   </property>\n</configuration>\n"})}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"fs.s3a.access.key"}),": the AWS access key ID."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"fs.s3a.secret.key"}),": the AWS secret key."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"fs.s3a.endpoint"}),": the AWS S3 endpoint to connect to."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"fs.s3a.connection.maximu``m"}),": the maximum number of concurrent connections from StarRocks to S3. If an error ",(0,s.jsx)(t.code,{children:"Timeout waiting for connection from poll"})," occurs during a query, you can set this parameter to a larger value."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"metadata-caching-strategy",children:"Metadata caching strategy"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["Hive partitions information and the related file information are cached in StarRocks. The cache is refreshed at intervals specified by ",(0,s.jsx)(t.code,{children:"hive_meta_cache_refresh_interval_s"}),". The default value is 7200.  ",(0,s.jsx)(t.code,{children:"hive_meta_cache_ttl_s"})," specifies the timeout duration of the cache and the default value is 86400.","\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["The cached data can also be refreshed manually.","\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{children:["If a partition is added or deleted from a table in Hive, you must run the ",(0,s.jsx)(t.code,{children:"REFRESH EXTERNAL TABLE hive_t"})," command to refresh the table metadata cached in StarRocks. ",(0,s.jsx)(t.code,{children:"hive_t"})," is the name of the Hive external table in StarRocks."]}),"\n",(0,s.jsxs)(t.li,{children:["If data in some Hive partitions is updated, you must refresh the cached data in StarRocks by running the ",(0,s.jsx)(t.code,{children:"REFRESH EXTERNAL TABLE hive_t PARTITION ('k1=01/k2=02', 'k1=03/k2=04')"})," command. ",(0,s.jsx)(t.code,{children:"hive_t"})," is the name of the Hive external table in StarRocks. ",(0,s.jsx)(t.code,{children:"'k1=01/k2=02'"})," and ",(0,s.jsx)(t.code,{children:"'k1=03/k2=04'"})," are the names of Hive partitions whose data is updated."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"starrocks-external-table",children:"StarRocks external table"}),"\n",(0,s.jsxs)(t.p,{children:["From StarRocks 1.19 onwards, StarRocks allows you to use a StarRocks external table to write data from one StarRocks cluster to another. This achieves read-write separation and provides better resource isolation. You can first create a destination table in the destination StarRocks cluster. Then, in the source StarRocks cluster, you can create a StarRocks external table that has the same schema as the destination table and specify the information of the destination cluster and table in the ",(0,s.jsx)(t.code,{children:"PROPERTIES"})," field."]}),"\n",(0,s.jsx)(t.p,{children:"Data can be written from  a source cluster to a  destination cluster by using INSERT INTO statement to write into a StarRocks external table. It can help realize the following goals:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Data synchronization between StarRocks clusters."}),"\n",(0,s.jsx)(t.li,{children:"Read-write separation. Data is written to the source cluster, and data changes from the source cluster are synchronized to the destination cluster, which provides query services."}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"The following code shows how to create a destination table and an external table."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-SQL",children:'# Create a destination table in the destination StarRocks cluster.\nCREATE TABLE t\n(\n    k1 DATE,\n    k2 INT,\n    k3 SMALLINT,\n    k4 VARCHAR(2048),\n    k5 DATETIME\n)\nENGINE=olap\nDISTRIBUTED BY HASH(k1) BUCKETS 10;\n\n# Create an external table in the source StarRocks cluster.\nCREATE EXTERNAL TABLE external_t\n(\n    k1 DATE,\n    k2 INT,\n    k3 SMALLINT,\n    k4 VARCHAR(2048),\n    k5 DATETIME\n)\nENGINE=olap\nDISTRIBUTED BY HASH(k1) BUCKETS 10\nPROPERTIES\n(\n    "host" = "127.0.0.1",\n    "port" = "9020",\n    "user" = "user",\n    "password" = "passwd",\n    "database" = "db_test",\n    "table" = "t"\n);\n\n# Write data from a source cluster to a destination cluster by writing data into the StarRocks external table. The second statement is recommended for the production environment.\ninsert into external_t values (\'2020-10-11\', 1, 1, \'hello\', \'2020-10-11 10:00:00\');\ninsert into external_t select * from other_table;\n'})}),"\n",(0,s.jsx)(t.p,{children:"Parameters\uff1a"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"EXTERNAL:"})," This keyword indicates that the table to be created is an external table."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"host:"})," This parameter specifies the IP address of the leader FE node of the destination StarRocks cluster."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"port:"}),"  This parameter specifies the RPC port of the leader FE node of the destination StarRocks cluster. You can set this parameter based on the rpc_port configuration in the ",(0,s.jsx)(t.strong,{children:"fe/fe.conf"})," file."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"user:"})," This parameter specifies the username used to access the destination StarRocks cluster."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"password:"})," This parameter specifies the password used to access the destination StarRocks cluster."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"database:"})," This parameter specifies the database to which the destination table belongs."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"table:"})," This parameter specifies the name of the destination table."]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"The following limits apply when you use a StarRocks external table:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"You can only run the INSERT INTO and SHOW CREATE TABLE commands on a StarRocks external table. Other data writing methods are not supported. In addition, you cannot query data from a StarRocks external table or perform DDL operations on the external table."}),"\n",(0,s.jsx)(t.li,{children:"The syntax of creating an external table is the same as creating a normal table, but the column names and other information in the external table must be the same as the destination table."}),"\n",(0,s.jsx)(t.li,{children:"The external table synchronizes table metadata from the destination table every 10 seconds. If a DDL operation is performed on the destination table, there may be a delay for data synchronization between the two tables."}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"apache-iceberg-external-table",children:"Apache Iceberg external table"}),"\n",(0,s.jsx)(t.p,{children:"StarRocks allows you to query data in Apache Iceberg by using an external table, which achieves blazing-fast analytics on data lakes. This topic describes how to use an external table in StarRocks to query Apache Iceberg data."}),"\n",(0,s.jsx)(t.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsx)(t.p,{children:"StarRocks has permissions to access the Hive metastore, HDFS cluster, and object storage bucket that corresponds to Apache Iceberg."}),"\n",(0,s.jsx)(t.h3,{id:"precautions",children:"Precautions"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"The Iceberg external table is read-only and can only be used for data queries."}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:["Only Iceberg V1 (copy on write) tables are supported. Iceberg V2 (merge on read) tables are not supported. For the differences between V1 and V2 tables, visit the ",(0,s.jsx)(t.a,{href:"https://iceberg.apache.org/#spec/#format-versioning",children:"official website of Apache Iceberg"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"The compression formats of Iceberg data files must be GZIP (default value), ZSTD, LZ4, and SNAPPY."}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"The Iceberg catalog type must be a Hive catalog. The data storage format must be Parquet or ORC."}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:["Currently, StarRocks cannot synchronize ",(0,s.jsx)(t.a,{href:"https://iceberg.apache.org/#evolution#schema-evolution",children:"schema evolution"})," from Apache Iceberg. If the schema of the source Iceberg table changes, you must delete the Iceberg external table that corresponds to the source table and create another one in StarRocks."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"procedure",children:"Procedure"}),"\n",(0,s.jsx)(t.h4,{id:"step-1-create-and-manage-iceberg-resources",children:"Step 1: Create and manage Iceberg resources"}),"\n",(0,s.jsx)(t.p,{children:"Before you create a database and Iceberg external table in StarRocks, you must create an Iceberg resource in StarRocks. The resource manages the connection information with the Iceberg data source. After the resource is created, you can create an Iceberg external table."}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:["If the metadata of an Iceberg table is obtained from a Hive metastore, you can create a resource and set the catalog type to ",(0,s.jsx)(t.code,{children:"HIVE"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:["If the metadata of an Iceberg table is obtained from other services, you need to create a custom catalog. Then create a resource and set the catalog type to ",(0,s.jsx)(t.code,{children:"CUSTOM"}),"."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.h5,{id:"create-a-resource-whose-catalog-type-is-hive",children:["Create a resource whose catalog type is ",(0,s.jsx)(t.code,{children:"HIVE"})]}),"\n",(0,s.jsxs)(t.p,{children:["For example, create a resource named ",(0,s.jsx)(t.code,{children:"iceberg0"})," and set the catalog type to ",(0,s.jsx)(t.code,{children:"HIVE"}),"."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-SQL",children:'CREATE EXTERNAL RESOURCE "iceberg0" \n\nPROPERTIES ( \n\n"type" = "iceberg", \n\n"starrocks.catalog-type"="HIVE", \n\n"iceberg.catalog.hive.metastore.uris"="thrift://192.168.0.81:9083" \n\n);\n'})}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Parameter"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"type"}),(0,s.jsxs)(t.td,{children:["The resource type. Set the value to ",(0,s.jsx)(t.code,{children:"iceberg"}),"."]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"starrocks.catalog-type"}),(0,s.jsxs)(t.td,{children:["The catalog type. Only the Hive catalog is supported. The value is ",(0,s.jsx)(t.code,{children:"HIVE"}),"."]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"iceberg.catalog.hive.metastore.uris"}),(0,s.jsx)(t.td,{children:"The thrift URI of the Hive metastore. Apache Iceberg uses the Hive catalog to access the Hive metastore and create and manage tables. You must pass in the thrift URI of the Hive metastore. The parameter value is in the following format: thrift://< Hive metadata IP address >:< Port number >. The port number defaults to 9083."})]})]})]}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Parameter"})}),(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Description"})})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"type"}),(0,s.jsxs)(t.td,{children:["The resource type. Set the value to ",(0,s.jsx)(t.code,{children:"iceberg"}),"."]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"starrocks.catalog-type"}),(0,s.jsxs)(t.td,{children:["The catalog type of the resource. Both Hive catalog and custom catalog are supported. If you specify a Hive catalog, set the value to ",(0,s.jsx)(t.code,{children:"HIVE"}),".If you specify a custom catalog, set the value to ",(0,s.jsx)(t.code,{children:"CUSTOM"}),"."]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"iceberg.catalog.hive.metastore.uris"}),(0,s.jsxs)(t.td,{children:["The URI of the Hive metastore. The parameter value is in the following format: ",(0,s.jsx)(t.code,{children:"thrift://< IP address of Iceberg metadata >:< port number >"}),". The port number defaults to 9083. Apache Iceberg uses a Hive catalog to access the Hive metastore and then queries the metadata of Iceberg tables."]})]})]})]}),"\n",(0,s.jsxs)(t.h5,{id:"create-a-resource-whose-catalog-type-is-custom",children:["Create a resource whose catalog type is ",(0,s.jsx)(t.code,{children:"CUSTOM"})]}),"\n",(0,s.jsxs)(t.p,{children:["A custom catalog needs to inherit the abstract class BaseMetastoreCatalog, and you need to implement the IcebergCatalog interface. For more information about how to create a custom catalog, see ",(0,s.jsx)(t.a,{href:"https://github.com/StarRocks/starrocks/blob/main/fe/fe-core/src/main/java/com/starrocks/external/iceberg/IcebergHiveCatalog.java",children:"IcebergHiveCatalog"}),". Additionally, the class name of a custom catalog cannot be duplicated with the name of the class that already exists in StarRock. After the catalog is created, package the catalog and its related files, and place them under the ",(0,s.jsx)(t.strong,{children:"fe/lib"})," path of each frontend (FE). Then restart each FE. After you complete the preceding operations, you can create a resource whose catalog is a custom catalog."]}),"\n",(0,s.jsxs)(t.p,{children:["For example, create a resource named ",(0,s.jsx)(t.code,{children:"iceberg1"})," and set the catalog type to ",(0,s.jsx)(t.code,{children:"CUSTOM"}),"."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-SQL",children:'CREATE EXTERNAL RESOURCE "iceberg1" \nPROPERTIES ( "type" = "iceberg", "starrocks.catalog-type"="CUSTOM", "iceberg.catalog-impl"="com.starrocks.IcebergCustomCatalog" \n);\n'})}),"\n",(0,s.jsx)(t.p,{children:"The following table describes the related parameters."}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Parameter"})}),(0,s.jsx)(t.th,{children:(0,s.jsx)(t.strong,{children:"Description"})})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"type"}),(0,s.jsxs)(t.td,{children:["The resource type. Set the value to ",(0,s.jsx)(t.code,{children:"iceberg"}),"."]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"starrocks.catalog-type"}),(0,s.jsxs)(t.td,{children:["The catalog type of the resource. Both Hive catalog and custom catalog are supported. If you specify a Hive catalog, set the value to ",(0,s.jsx)(t.code,{children:"HIVE"}),".If you specify a custom catalog, set the value to ",(0,s.jsx)(t.code,{children:"CUSTOM"}),"."]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"iceberg.catalog-impl"}),(0,s.jsxs)(t.td,{children:["The fully qualified class name of the custom catalog. FEs search for the catalog based on this name. If the catalog contains custom configuration items, you must add them to the ",(0,s.jsx)(t.code,{children:"PROPERTIES"})," parameter as key-value pairs when you create an Iceberg external table."]})]})]})]}),"\n",(0,s.jsx)(t.h5,{id:"view-iceberg-resources",children:"View Iceberg resources"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-SQL",children:"SHOW RESOURCES;\n"})}),"\n",(0,s.jsx)(t.h5,{id:"drop-an-iceberg-resource",children:"Drop an Iceberg resource"}),"\n",(0,s.jsxs)(t.p,{children:["For example, drop a resource named ",(0,s.jsx)(t.code,{children:"iceberg0"}),"."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-SQL",children:'DROP RESOURCE "iceberg0";\n'})}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:"Dropping an Iceberg resource makes all Iceberg external tables that correspond to this resource unavailable. However, data in Apache Iceberg will not be lost. If you still need to query Iceberg data in StarRocks, create another Iceberg resource, database, and external table."}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"step-2-create-an-iceberg-database",children:"Step 2: Create an Iceberg database"}),"\n",(0,s.jsxs)(t.p,{children:["Run the following command to create an Iceberg database named ",(0,s.jsx)(t.code,{children:"iceberg_test"})," in StarRocks."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-SQL",children:"CREATE DATABASE iceberg_test; \n\n\n\nUSE iceberg_test; \n"})}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:"The database name in StarRocks can be different from the name of the source database in Iceberg."}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"step-3-create-an-iceberg-external-table",children:"Step 3: Create an Iceberg external table"}),"\n",(0,s.jsxs)(t.p,{children:["Run the following command to create an Iceberg external table named ",(0,s.jsx)(t.code,{children:"iceberg_tbl"})," in the Iceberg database ",(0,s.jsx)(t.code,{children:"iceberg_test"}),"."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-SQL",children:'CREATE EXTERNAL TABLE `iceberg_tbl` ( \n\n`id` bigint NULL, \n\n`data` varchar(200) NULL \n\n) ENGINE=ICEBERG \n\nPROPERTIES ( \n\n"resource" = "iceberg0", \n\n"database" = "iceberg", \n\n"table" = "iceberg_table" \n\n); \n'})}),"\n",(0,s.jsx)(t.p,{children:"The following table describes related parameters."}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Parameter"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"ENGINE"}),(0,s.jsxs)(t.td,{children:["The engine name. Set the value to ",(0,s.jsx)(t.code,{children:"ICEBERG"}),"."]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"resource"}),(0,s.jsx)(t.td,{children:"The name of the Iceberg resource in StarRocks."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"database"}),(0,s.jsx)(t.td,{children:"The name of the database in Iceberg."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"table"}),(0,s.jsx)(t.td,{children:"The name of the data table in Iceberg."})]})]})]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"The name of the external table can be different from the name of the Iceberg data table."}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"The column names of the external table must be the same as those in the Iceberg data table. The column order can be different."}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"You can select all or part of the columns in the Iceberg data table based on your business needs. The following table provides the mapping between data types supported by StarRocks and Iceberg."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Apache Iceberg"}),(0,s.jsx)(t.th,{children:"StarRocks"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"BOOLEAN"}),(0,s.jsx)(t.td,{children:"BOOLEAN"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"INT"}),(0,s.jsx)(t.td,{children:"TINYINT, SMALLINT, INT"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"LONG"}),(0,s.jsx)(t.td,{children:"BIGINT"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"FLOAT"}),(0,s.jsx)(t.td,{children:"FLOAT"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"DOUBLE"}),(0,s.jsx)(t.td,{children:"DOUBLE"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"DECIMAL(P,S)"}),(0,s.jsx)(t.td,{children:"DECIMAL"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"DATE"}),(0,s.jsx)(t.td,{children:"DATE, DATETIME"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"TIME"}),(0,s.jsx)(t.td,{children:"BIGINT"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"TIMESTAMP"}),(0,s.jsx)(t.td,{children:"DATETIME"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"STRING"}),(0,s.jsx)(t.td,{children:"STRING, VARCHAR"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"UUID"}),(0,s.jsx)(t.td,{children:"STRING, VARCHAR"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"FIXED(L)"}),(0,s.jsx)(t.td,{children:"CHAR"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"BINARY"}),(0,s.jsx)(t.td,{children:"VARCHAR"})]})]})]}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:"Currently, StarRocks does not support using an Iceberg external table to query Iceberg data whose data type is TIMESTAMPTZ, STRUCT, LIST, or MAP."}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"step-4-query-iceberg-data",children:"Step 4: Query Iceberg data"}),"\n",(0,s.jsx)(t.p,{children:"After the Iceberg external table is created, you can run the following command to directly query data in Apache Iceberg without having to import Iceberg data into StarRocks."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-SQL",children:"select count(*) from iceberg_tbl;\n"})}),"\n",(0,s.jsx)(t.h2,{id:"hudi-external-table",children:"Hudi external table"}),"\n",(0,s.jsx)(t.p,{children:"StarRocks allows you to query data from Hudi data lakes by using Hudi external tables, thus facilitating blazing-fast data lake analytics. This topic describes how to create a Hudi external table in your StarRocks cluster and use the Hudi external table to query data from a Hudi data lake."}),"\n",(0,s.jsx)(t.h3,{id:"before-you-begin",children:"Before you begin"}),"\n",(0,s.jsx)(t.p,{children:"Make sure that your StarRocks cluster is granted access to the Hive metastore, HDFS cluster, or bucket with which you can register Hudi tables."}),"\n",(0,s.jsx)(t.h3,{id:"precautions-1",children:"Precautions"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"Hudi external tables for Hudi are read-only and can be used only for queries."}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:["StarRocks supports Hudi Copy on Write (CoW) tables but not Hudi Merge on Read (MoR) tables. For information about the differences between CoW and MoR, see ",(0,s.jsx)(t.a,{href:"https://hudi.apache.org/docs/table_types/",children:"Table & Query Types"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"StarRocks supports the following compression formats for Hudi files: gzip, zstd, LZ4, and Snappy. The default compression format for Hudi files is gzip."}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:["StarRocks cannot synchronize schema changes from Hudi managed tables. For more information, see ",(0,s.jsx)(t.a,{href:"https://hudi.apache.org/docs/schema_evolution/",children:"Schema Evolution"}),". If the schema of a Hudi managed table is changed, you must delete the associated Hudi external table from your StarRocks cluster and then re-create that external table."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"procedure-1",children:"Procedure"}),"\n",(0,s.jsx)(t.h4,{id:"step-1-create-and-manage-hudi-resources",children:"Step 1: Create and manage Hudi resources"}),"\n",(0,s.jsx)(t.p,{children:"You must create Hudi resources in your StarRocks cluster. The Hudi resources are used to manage the Hudi databases and external tables that you create in your StarRocks cluster."}),"\n",(0,s.jsx)(t.h5,{id:"create-a-hudi-resource",children:"Create a Hudi resource"}),"\n",(0,s.jsxs)(t.p,{children:["Execute the following statement to create a Hudi resource named ",(0,s.jsx)(t.code,{children:"hudi0"}),":"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-SQL",children:'CREATE EXTERNAL RESOURCE "hudi0" \nPROPERTIES ( \n    "type" = "hudi", \n    "hive.metastore.uris" = "thrift://192.168.7.251:9083"\n);\n'})}),"\n",(0,s.jsx)(t.p,{children:"The following table describes the parameters."}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Parameter"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"type"}),(0,s.jsx)(t.td,{children:"The type of the Hudi resource. Set the vaue to hudi."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"hive.metastore.uris"}),(0,s.jsxs)(t.td,{children:["The Thrift URI of the Hive metastore to which the Hudi resource connects. After connecting the Hudi resource to a Hive metastore, you can create and manage Hudi tables by using Hive. The Thrift URI is in the ",(0,s.jsx)(t.code,{children:"<IP address of the Hive metastore\\>:<Port number of the Hive metastore\\>"})," format. The default port number is 9083."]})]})]})]}),"\n",(0,s.jsxs)(t.p,{children:["From v2.3 onwards, StarRocks allows changing the ",(0,s.jsx)(t.code,{children:"hive.metastore.uris"})," value of a Hudi resource. For more information, see ",(0,s.jsx)(t.a,{href:"https://docs.starrocks.com/en-us/2.3/sql-reference/sql-statements/data-definition/ALTER_RESOURCE",children:"ALTER RESOURCE"}),"."]}),"\n",(0,s.jsx)(t.h5,{id:"view-hudi-resources",children:"View Hudi resources"}),"\n",(0,s.jsx)(t.p,{children:"Execute the following statement to view all Hudi resources that are created in your StarRocks cluster:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-SQL",children:"SHOW RESOURCES;\n"})}),"\n",(0,s.jsx)(t.h5,{id:"delete-a-hudi-resource",children:"Delete a Hudi resource"}),"\n",(0,s.jsxs)(t.p,{children:["Execute the following statement to delete the Hudi resource named ",(0,s.jsx)(t.code,{children:"hudi0"}),":"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-SQL",children:'DROP RESOURCE "hudi0";\n'})}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:"Note:"}),"\n",(0,s.jsx)(t.p,{children:"Deleting a Hudi resource causes unavailability of all Hudi external tables that are created by using that Hudi resource. However, the deletion does not affect your data stored in Hudi. If you still want to query your data from Hudi by using StarRocks, you must re-create Hudi resources, Hudi databases, and Hudi external tables in your StarRocks cluster."}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"step-2-create-hudi-databases",children:"Step 2: Create Hudi databases"}),"\n",(0,s.jsxs)(t.p,{children:["Execute the following statement to create and open a Hudi database named ",(0,s.jsx)(t.code,{children:"hudi_test"})," in your StarRocks cluster:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-SQL",children:"CREATE DATABASE hudi_test; \nUSE hudi_test; \n"})}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:"Note:"}),"\n",(0,s.jsx)(t.p,{children:"The name that you specify for the Hudi database in your StarRocks cluster does not need to be the same as the associated database in Hudi."}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"step-3-create-hudi-external-tables",children:"Step 3: Create Hudi external tables"}),"\n",(0,s.jsxs)(t.p,{children:["Execute the following statement to create a Hudi external table named ",(0,s.jsx)(t.code,{children:"hudi_tbl"})," in the ",(0,s.jsx)(t.code,{children:"hudi_test"})," Hudi database:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-SQL",children:'CREATE EXTERNAL TABLE `hudi_tbl` ( \n    `id` bigint NULL, \n    `data` varchar(200) NULL \n) ENGINE=HUDI \nPROPERTIES ( \n    "resource" = "hudi0", \n    "database" = "hudi", \n    "table" = "hudi_table" \n); \n'})}),"\n",(0,s.jsx)(t.p,{children:"The following table describes the parameters."}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Parameter"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"ENGINE"}),(0,s.jsxs)(t.td,{children:["The query engine of the Hudi external table. Set the value to ",(0,s.jsx)(t.code,{children:"HUDI"}),"."]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"resource"}),(0,s.jsx)(t.td,{children:"The name of the Hudi resource in your StarRocks cluster."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"database"}),(0,s.jsx)(t.td,{children:"The name of the Hudi database to which the Hudi external table belongs in your StarRocks cluster."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"table"}),(0,s.jsx)(t.td,{children:"The Hudi managed table with which the Hudi external table is associated."})]})]})]}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:"Note:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"The name that you specify for the Hudi external table does not need to be the same as the associated Hudi managed table."}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"The columns in the Hudi external table must have the same names but can be in a different sequence compared to their counterpart columns in the associated Hudi managed table."}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"You can select some or all columns from the associated Hudi managed table and create only the selected columns in the Hudi external table. The following table lists the mapping between the data types supported by Hudi and the data types supported by StarRocks."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Data types supported by Hudi"}),(0,s.jsx)(t.th,{children:"Data types supported by StarRocks"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"BOOLEAN"}),(0,s.jsx)(t.td,{children:"BOOLEAN"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"INT"}),(0,s.jsx)(t.td,{children:"TINYINT/SMALLINT/INT"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"DATE"}),(0,s.jsx)(t.td,{children:"DATE"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"TimeMillis/TimeMicros"}),(0,s.jsx)(t.td,{children:"TIME"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"LONG"}),(0,s.jsx)(t.td,{children:"BIGINT"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"FLOAT"}),(0,s.jsx)(t.td,{children:"FLOAT"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"DOUBLE"}),(0,s.jsx)(t.td,{children:"DOUBLE"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"STRING"}),(0,s.jsx)(t.td,{children:"CHAR/VARCHAR"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"ARRAY"}),(0,s.jsx)(t.td,{children:"ARRAY"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"DECIMAL"}),(0,s.jsx)(t.td,{children:"DECIMAL"})]})]})]}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:"If some columns of a Hudi managed table are any of the FIXED, ENUM, UNION, MAP, and BYTES data types, you cannot access these columns by creating a Hudi external table associated with that Hudi managed table."}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"step-4-query-data-from-a-hudi-external-table",children:"Step 4: Query data from a Hudi external table"}),"\n",(0,s.jsx)(t.p,{children:"After you create a Hudi external table associated with a specific Hudi managed table, you do not need to load data into the Hudi external table. To query data from Hudi, execute the following statement:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-SQL",children:"SELECT COUNT(*) FROM hudi_tbl;\n"})})]})}const h=function(e={}){const{wrapper:t}=Object.assign({},(0,r.ah)(),e.components);return t?(0,s.jsx)(t,Object.assign({},e,{children:(0,s.jsx)(o,e)})):o(e)}},11151:(e,t,n)=>{n.d(t,{Zo:()=>c,ah:()=>a});var s=n(67294);const r=s.createContext({});function a(e){const t=s.useContext(r);return s.useMemo((()=>"function"==typeof e?e(t):{...t,...e}),[t,e])}const i={};function c({components:e,children:t,disableParentContext:n}){let c;return c=n?"function"==typeof e?e({}):e||i:a(e),s.createElement(r.Provider,{value:c},t)}}}]);