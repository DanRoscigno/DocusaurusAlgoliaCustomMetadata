"use strict";(self.webpackChunkstarrocks=self.webpackChunkstarrocks||[]).push([[26370],{31232:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>a,toc:()=>c});var s=t(85893),r=t(11151);const i={displayed_sidebar:"English"},o="Load data by using flink-connector-starrocks",a={id:"loading/Flink-connector-starrocks",title:"Load data by using flink-connector-starrocks",description:"This topic describes how to load data from Apache Flink\xae to StarRocks.",source:"@site/versioned_docs/version-2.0/loading/Flink-connector-starrocks.md",sourceDirName:"loading",slug:"/loading/Flink-connector-starrocks",permalink:"/docs/2.0/loading/Flink-connector-starrocks",draft:!1,unlisted:!1,editUrl:"https://github.com/StarRocks/starrocks/edit/main/docs/loading/Flink-connector-starrocks.md",tags:[],version:"2.0",frontMatter:{displayed_sidebar:"English"},sidebar:"English",previous:{title:"ETL When Loading",permalink:"/docs/2.0/loading/Etl_in_loading"},next:{title:"Synchronize data from MySQL",permalink:"/docs/2.0/loading/Flink_cdc_load"}},d={},c=[{value:"Overview",id:"overview",level:2},{value:"Procedure",id:"procedure",level:2},{value:"Usage notes",id:"usage-notes",level:2}];function l(e){const n=Object.assign({h1:"h1",p:"p",h2:"h2",ol:"ol",li:"li",a:"a",strong:"strong",code:"code",pre:"pre",ul:"ul",table:"table",thead:"thead",tr:"tr",th:"th",tbody:"tbody",td:"td",div:"div"},(0,r.ah)(),e.components);return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"load-data-by-using-flink-connector-starrocks",children:"Load data by using flink-connector-starrocks"}),"\n",(0,s.jsx)(n.p,{children:"This topic describes how to load data from Apache Flink\xae to StarRocks."}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"The flink-connector-jdbc tool provided by Apache Flink\xae may not meet your performance requirements in certain scenarios. Therefore we provide a new connector named flink-connector-starrocks, which can cache data and then load data at a time by using Stream Load."}),"\n",(0,s.jsx)(n.h2,{id:"procedure",children:"Procedure"}),"\n",(0,s.jsx)(n.p,{children:"To load data from Apache Flink\xae into StarRocks by using flink-connector-starrocks, perform the following steps:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Download the ",(0,s.jsx)(n.a,{href:"https://github.com/StarRocks/flink-connector-starrocks",children:"source code"})," of flink-connector-starrocks."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Find a file named ",(0,s.jsx)(n.strong,{children:"pom.xml"}),". Add the following code snippet to ",(0,s.jsx)(n.strong,{children:"pom.xml"})," and replace ",(0,s.jsx)(n.code,{children:"x.x.x"})," in the code snippet with the latest version number of flink-connector-starrocks."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-Plain_Text",children:"<dependency>\n\n    <groupId>com.starrocks</groupId>\n\n    <artifactId>flink-connector-starrocks</artifactId>\n\n    \x3c!-- for flink-1.11, flink-1.12 --\x3e\n\n    <version>x.x.x_flink-1.11</version>\n\n    \x3c!-- for flink-1.13 --\x3e\n\n    <version>x.x.x_flink-1.13</version>\n\n</dependency>\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Use one of the following methods to load data"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Load data as raw JSON string streams."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-Plain_Text",children:'// -------- sink with raw json string stream --------\n\nfromElements(new String[]{\n\n    "{\\"score\\": \\"99\\", \\"name\\": \\"stephen\\"}",\n\n    "{\\"score\\": \\"100\\", \\"name\\": \\"lebron\\"}"\n\n}).addSink(\n\n    StarRocksSink.sink(\n\n        // the sink options\n\n        StarRocksSinkOptions.builder()\n\n            .withProperty("jdbc-url", "jdbc:mysql://fe1_ip:query_port,fe2_ip:query_port,fe3_ip:query_port?xxxxx")\n\n            .withProperty("load-url", "fe1_ip:http_port;fe2_ip:http_port;fe3_ip:http_port")\n\n            .withProperty("username", "xxx")\n\n            .withProperty("password", "xxx")\n\n            .withProperty("table-name", "xxx")\n\n            .withProperty("database-name", "xxx")\n\n            .withProperty("sink.properties.format", "json")\n\n            .withProperty("sink.properties.strip_outer_array", "true")\n\n            .build()\n\n    )\n\n);\n\n\n\n\n\n// -------- sink with stream transformation --------\n\nclass RowData {\n\n    public int score;\n\n    public String name;\n\n    public RowData(int score, String name) {\n\n        ......\n\n    }\n\n}\n\nfromElements(\n\n    new RowData[]{\n\n        new RowData(99, "stephen"),\n\n        new RowData(100, "lebron")\n\n    }\n\n).addSink(\n\n    StarRocksSink.sink(\n\n        // the table structure\n\n        TableSchema.builder()\n\n            .field("score", DataTypes.INT())\n\n            .field("name", DataTypes.VARCHAR(20))\n\n            .build(),\n\n        // the sink options\n\n        StarRocksSinkOptions.builder()\n\n            .withProperty("jdbc-url", "jdbc:mysql://fe1_ip:query_port,fe2_ip:query_port,fe3_ip:query_port?xxxxx")\n\n            .withProperty("load-url", "fe1_ip:http_port;fe2_ip:http_port;fe3_ip:http_port")\n\n            .withProperty("username", "xxx")\n\n            .withProperty("password", "xxx")\n\n            .withProperty("table-name", "xxx")\n\n            .withProperty("database-name", "xxx")\n\n            .withProperty("sink.properties.format", "csv")  \n\n            .withProperty("sink.properties.column_separator", "\\\\x01")\n\n            .withProperty("sink.properties.row_delimiter", "\\\\x02")\n\n            .build(),\n\n        // set the slots with streamRowData\n\n        (slots, streamRowData) -> {\n\n            slots[0] = streamRowData.score;\n\n            slots[1] = streamRowData.name;\n\n        }\n\n    )\n\n);\n'})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Load data as tables."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-Plain_Text",children:"// create a table with `structure` and `properties`\n\n// Needed: Add `com.starrocks.connector.flink.table.StarRocksDynamicTableSinkFactory` to: `src/main/resources/META-INF/services/org.apache.flink.table.factories.Factory`\n\ntEnv.executeSql(\n\n    \"CREATE TABLE USER_RESULT(\" +\n\n        \"name VARCHAR,\" +\n\n        \"score BIGINT\" +\n\n    \") WITH ( \" +\n\n        \"'connector' = 'starrocks',\" +\n\n        \"'jdbc-url'='jdbc:mysql://fe1_ip:query_port,fe2_ip:query_port,fe3_ip:query_port?xxxxx',\" +\n\n        \"'load-url'='fe1_ip:http_port;fe2_ip:http_port;fe3_ip:http_port',\" +\n\n        \"'database-name' = 'xxx',\" +\n\n        \"'table-name' = 'xxx',\" +\n\n        \"'username' = 'xxx',\" +\n\n        \"'password' = 'xxx',\" +\n\n        \"'sink.buffer-flush.max-rows' = '1000000',\" +\n\n        \"'sink.buffer-flush.max-bytes' = '300000000',\" +\n\n        \"'sink.buffer-flush.interval-ms' = '5000',\" +\n\n        \"'sink.properties.column_separator' = '\\\\x01',\" +\n\n        \"'sink.properties.row_delimiter' = '\\\\x02',\" +\n\n        \"'sink.max-retries' = '3'\" +\n\n        \"'sink.properties.*' = 'xxx'\" + // stream load properties like `'sink.properties.columns' = 'k1, v1'`\n\n    \")\"\n\n);\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["The following table describes the ",(0,s.jsx)(n.code,{children:"sink"})," options that you can configure when you load data as tables."]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:"Option"})}),(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:"Required"})}),(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:"Default value"})}),(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:"Data type"})}),(0,s.jsx)(n.th,{children:(0,s.jsx)(n.strong,{children:"Description"})})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"connector"}),(0,s.jsx)(n.td,{children:"Yes"}),(0,s.jsx)(n.td,{children:"NONE"}),(0,s.jsx)(n.td,{children:"STRING"}),(0,s.jsx)(n.td,{children:"The connector that you want to use. The value must be starrocks."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"jdbc-url"}),(0,s.jsx)(n.td,{children:"Yes"}),(0,s.jsx)(n.td,{children:"NONE"}),(0,s.jsx)(n.td,{children:"STRING"}),(0,s.jsx)(n.td,{children:"The URL that is used to query data from StarRocks."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"load-url"}),(0,s.jsx)(n.td,{children:"Yes"}),(0,s.jsx)(n.td,{children:"NONE"}),(0,s.jsx)(n.td,{children:"STRING"}),(0,s.jsxs)(n.td,{children:["The URL that is used to load all data in a time. Format: fe_ip",(0,s.jsx)(n.div,{}),";fe_ip",(0,s.jsx)(n.div,{}),"."]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"database-name"}),(0,s.jsx)(n.td,{children:"Yes"}),(0,s.jsx)(n.td,{children:"NONE"}),(0,s.jsx)(n.td,{children:"STRING"}),(0,s.jsx)(n.td,{children:"The name of the StarRocks database into which you want to load data."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"table-name"}),(0,s.jsx)(n.td,{children:"Yes"}),(0,s.jsx)(n.td,{children:"NONE"}),(0,s.jsx)(n.td,{children:"STRING"}),(0,s.jsx)(n.td,{children:"The name of the table that you want to use to load data into StarRocks."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"username"}),(0,s.jsx)(n.td,{children:"Yes"}),(0,s.jsx)(n.td,{children:"NONE"}),(0,s.jsx)(n.td,{children:"STRING"}),(0,s.jsx)(n.td,{children:"The username of the account that you want to use to load data into StarRocks."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"password"}),(0,s.jsx)(n.td,{children:"Yes"}),(0,s.jsx)(n.td,{children:"NONE"}),(0,s.jsx)(n.td,{children:"STRING"}),(0,s.jsx)(n.td,{children:"The password of the preceding account."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"sink.semantic"}),(0,s.jsx)(n.td,{children:"No"}),(0,s.jsx)(n.td,{children:"at-least-once"}),(0,s.jsx)(n.td,{children:"STRING"}),(0,s.jsxs)(n.td,{children:["The semantics that is supported by your sink. Valid values: ",(0,s.jsx)(n.strong,{children:"at-least-once"})," and ",(0,s.jsx)(n.strong,{children:"exactly-once"}),". If you specify the value as exactly-once, ",(0,s.jsx)(n.code,{children:"sink.buffer-flush.max-bytes"}),", ",(0,s.jsx)(n.code,{children:"sink.buffer-flush.max-bytes"}),", and ",(0,s.jsx)(n.code,{children:"sink.buffer-flush.interval-ms"})," are invalid."]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"sink.buffer-flush.max-bytes"}),(0,s.jsx)(n.td,{children:"No"}),(0,s.jsx)(n.td,{children:"94371840(90M)"}),(0,s.jsx)(n.td,{children:"STRING"}),(0,s.jsx)(n.td,{children:"The maximum size of data that can be loaded into StarRocks at a time. Valid values: 64 MB to 10 GB."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"sink.buffer-flush.max-rows"}),(0,s.jsx)(n.td,{children:"No"}),(0,s.jsx)(n.td,{children:"500000"}),(0,s.jsx)(n.td,{children:"STRING"}),(0,s.jsx)(n.td,{children:"The maximum number of rows that can be loaded into StarRocks at a time. Valid values: 64000 to 5000000."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"sink.buffer-flush.interval-ms"}),(0,s.jsx)(n.td,{children:"No"}),(0,s.jsx)(n.td,{children:"300000"}),(0,s.jsx)(n.td,{children:"STRING"}),(0,s.jsx)(n.td,{children:"The interval at which data is flushed. Valid values: 1000 to 3600000. Unit: ms."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"sink.max-retries"}),(0,s.jsx)(n.td,{children:"No"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"STRING"}),(0,s.jsx)(n.td,{children:"The number of times that the system retries to perform the Stream Load. Valid values: 0 to 10."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"sink.connect.timeout-ms"}),(0,s.jsx)(n.td,{children:"No"}),(0,s.jsx)(n.td,{children:"1000"}),(0,s.jsx)(n.td,{children:"STRING"}),(0,s.jsx)(n.td,{children:"The period of time after which the stream load times out. Valid values: 100 to 60000. Unit: ms."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"sink.properties.*"}),(0,s.jsx)(n.td,{children:"No"}),(0,s.jsx)(n.td,{children:"NONE"}),(0,s.jsx)(n.td,{children:"STRING"}),(0,s.jsx)(n.td,{children:"The properties of the stream load. The properties include k1, k2, and k3."})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"usage-notes",children:"Usage notes"}),"\n",(0,s.jsx)(n.p,{children:"When you load data from Apache Flink\xae into StarRocks, take note of the following points:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"If you specify the exactly-once semantics, the two-phase commit (2PC) protocol must be supported to ensure efficient data loading. StarRocks does not support this protocol. Therefore we need to rely on Apache Flink\xae to achieve exactly-once. The overall process is as follows:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Save data and its label at each checkpoint that is completed at a specific checkpoint interval."}),"\n",(0,s.jsx)(n.li,{children:"After data and labels are saved, block the flushing of data cached in the state at the first invoke after each checkpoint is completed."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"If StarRocks unexpectedly exits, the operators for Apache Flink\xae sink streaming are blocked for a long time and Apache Flink\xae issues a monitoring alert or shuts down."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["By default, data is loaded in the CSV format. You can set the ",(0,s.jsx)(n.code,{children:"sink.properties.row_delimiter"})," parameter to ",(0,s.jsx)(n.code,{children:"\\\\x02"})," to specify a row separator and set the ",(0,s.jsx)(n.code,{children:"sink.properties.column_separator"})," parameter to ",(0,s.jsx)(n.code,{children:"\\\\x01"})," to specify a column separator."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"If data loading pauses, you can increase the memory of the Flink task."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["If the preceding code runs as expected and StarRocks can receive data, but the data loading fails, check whether your machine can access the HTTP port of the backends (BEs) in your StarRocks cluster. If you can successfully ping the HTTP port returned by the execution of the SHOW BACKENDS command in your StarRocks cluster, your machine can access the HTTP port of the backends (BEs) in your StarRocks cluster. For example, a machine has a public IP address and a private IP address, the HTTP ports of frontends (FEs) and BEs can be accessed through the public IP address of the FEs and BEs, the IP address that is bounded with your StarRocks cluster is the private IP address, and the value of ",(0,s.jsx)(n.code,{children:"loadurl"})," for the Flink task is the HTTP port of the public IP address of the FEs. The FEs forwards the data loading task to the private IP address of the BEs. In this example, if the machine cannot ping the private IP address of the BEs, the data loading fails."]}),"\n"]}),"\n"]})]})}const h=function(e={}){const{wrapper:n}=Object.assign({},(0,r.ah)(),e.components);return n?(0,s.jsx)(n,Object.assign({},e,{children:(0,s.jsx)(l,e)})):l(e)}},11151:(e,n,t)=>{t.d(n,{Zo:()=>a,ah:()=>i});var s=t(67294);const r=s.createContext({});function i(e){const n=s.useContext(r);return s.useMemo((()=>"function"==typeof e?e(n):{...n,...e}),[n,e])}const o={};function a({components:e,children:n,disableParentContext:t}){let a;return a=t?"function"==typeof e?e({}):e||o:i(e),s.createElement(r.Provider,{value:a},n)}}}]);