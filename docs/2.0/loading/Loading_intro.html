<!doctype html>
<html lang="en-US" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-2.0 docs-doc-page docs-doc-id-loading/Loading_intro" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.0-beta.0">
<title data-rh="true">Data import | StarRocks</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://danroscigno.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://danroscigno.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://danroscigno.github.io/docs/2.0/loading/Loading_intro"><meta data-rh="true" property="og:locale" content="en_US"><meta data-rh="true" property="og:locale:alternate" content="zh_CN"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="2.0"><meta data-rh="true" name="docusaurus_tag" content="docs-default-2.0"><meta data-rh="true" name="docsearch:version" content="2.0"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-2.0"><meta data-rh="true" property="og:title" content="Data import | StarRocks"><meta data-rh="true" name="description" content="StarRocks supports multiple data models (refer to Table Design chapter) for different business scenarios. The data import function aims to clean and transform the raw data according to the specific model and load it into StarRocks."><meta data-rh="true" property="og:description" content="StarRocks supports multiple data models (refer to Table Design chapter) for different business scenarios. The data import function aims to clean and transform the raw data according to the specific model and load it into StarRocks."><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://danroscigno.github.io/docs/2.0/loading/Loading_intro"><link data-rh="true" rel="alternate" href="https://danroscigno.github.io/docs/2.0/loading/Loading_intro" hreflang="en-US"><link data-rh="true" rel="alternate" href="https://danroscigno.github.io/zh/docs/2.0/loading/Loading_intro" hreflang="zh-CN"><link data-rh="true" rel="alternate" href="https://danroscigno.github.io/docs/2.0/loading/Loading_intro" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://ER08SJMRY1-dsn.algolia.net" crossorigin="anonymous"><link rel="search" type="application/opensearchdescription+xml" title="StarRocks" href="/opensearch.xml"><link rel="stylesheet" href="/assets/css/styles.62f01ed5.css">
<script src="/assets/js/runtime~main.3ec76a3f.js" defer="defer"></script>
<script src="/assets/js/main.bda7b85e.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a href="https://www.starrocks.io/" target="_blank" rel="noopener noreferrer" class="navbar__brand"><div class="navbar__logo"><img src="/img/logo.svg" alt="StarRocks Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="StarRocks Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">StarRocks</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/2.0/administration/Build_in_docker">Documentation</a><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link" aria-haspopup="true" aria-expanded="false" role="button" href="/docs/2.0/administration/Build_in_docker">2.0</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/next/examples/introduction">Next</a></li><li><a class="dropdown__link" href="/docs/loading/Loading_intro">Latest-3.1</a></li><li><a class="dropdown__link" href="/docs/3.0/loading/Loading_intro">3.0</a></li><li><a class="dropdown__link" href="/docs/2.5/loading/Loading_intro">Stable-2.5</a></li><li><a class="dropdown__link" href="/docs/2.3/loading/Loading_intro">2.3</a></li><li><a class="dropdown__link" href="/docs/2.2/loading/Loading_intro">2.2</a></li><li><a class="dropdown__link" href="/docs/2.1/loading/Loading_intro">2.1</a></li><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/docs/2.0/loading/Loading_intro">2.0</a></li><li><a class="dropdown__link" href="/docs/1.19/development/Build_in_docker">1.19</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/docs/2.0/loading/Loading_intro" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en-US">English</a></li><li><a href="/zh/docs/2.0/loading/Loading_intro" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-CN">中文</a></li></ul></div></div><div class="navbar__items navbar__items--right"><a href="https://github.com/StarRocks/starrocks" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/2.0/administration/Build_in_docker">administration</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/2.0/faq/Deploy_faq">faq</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/2.0/introduction/StarRocks_intro">introduction</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/2.0/loading/BrokerLoad">loading</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/2.0/loading/BrokerLoad">Broker Load</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/2.0/loading/DataX-starrocks-writer">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/2.0/loading/Etl_in_loading">ETL When Loading</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/2.0/loading/Flink-connector-starrocks">Load data by using flink-connector-starrocks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/2.0/loading/Flink_cdc_load">Synchronize data from MySQL</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/2.0/loading/InsertInto">Insert Into Loading</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/2.0/loading/Json_loading">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/2.0/loading/Loading_intro">Data import</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/2.0/loading/RoutineLoad">Routine Load</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/2.0/loading/SparkLoad">Spark Load</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/2.0/loading/StreamLoad">Stream load</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/2.0/quick_start">quick_start</a><button aria-label="Expand sidebar category &#x27;quick_start&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/2.0/reference/Error_code">reference</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/2.0/release_notes/release-1.19">release_notes</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/2.0/table_design">Introduction</a><button aria-label="Expand sidebar category &#x27;Introduction&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/2.0/unloading/Export">unloading</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/2.0/using_starrocks/Array">using_starrocks</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><span class="breadcrumbs__link">loading</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Data import</span><meta itemprop="position" content="2"></li></ul></nav><span class="theme-doc-version-badge badge badge--secondary">Version: 2.0</span><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Data import</h1>
<p>StarRocks supports multiple data models (refer to <a href="/docs/2.0/table_design">Table Design</a> chapter) for different business scenarios. The data import function aims to clean and transform the raw data according to the specific model and load it into StarRocks.</p>
<p>StarRocks supports a variety of import methods. Users can choose the most suitable method based on the data size and import frequency. This section introduces the basic concepts, principles, system configuration, suitable scenarios of different import methods, as well as best practices and frequently asked questions.</p>
<blockquote>
<p>Note: It is recommended to read this whole section first, and then dive into the details of your selected import method.</p>
</blockquote>
<p><img loading="lazy" alt="Data Import Overview" src="/assets/images/4.1.1-746d664032a8ca46d5aadc3e964750b3.png" width="1048" height="446" class="img_ev3q">
Choose the import methods based on your data source.</p>
<ul>
<li>Offline data import. If the data source is Hive/HDFS, <a href="/docs/2.0/loading/BrokerLoad">Broker Load</a> is recommended. If there are many data tables, consider using <a href="/docs/2.0/using_starrocks/External_table">Hive external table</a> for direct query.The performance may be worse than <code>Broker Load</code>, but it doesn’t require data relocation. If a table has a large data volume, or needs the global data dictionary for precise deduplication, choose <a href="/docs/2.0/loading/SparkLoad">Spark  Load</a>.</li>
<li>Real-time data import. It is recommended to import log and binlog data to StarRocks via <a href="/docs/2.0/loading/RoutineLoad">Routine load</a> after they are synchronized to Kafka. StarRocks has a standard <a href="/docs/2.0/loading/Flink-connector-starrocks">Flink-connector</a> to facilitate the use of Flink jobs.</li>
<li>Write to StarRocks programmatically. It is recommended to use <a href="/docs/2.0/loading/StreamLoad">Stream  Load</a>.</li>
<li>Text file import. It is recommended to use <code>Stream  Load</code>.</li>
<li>Mysql data import. It is recommend to use <a href="/docs/2.0/using_starrocks/External_table#MySQLExternalTables">MySQL external table</a> to import (<code>insert into new_table select * from external_table</code>)</li>
<li>Other data sources to import. It is recommended to use DataX import. StarRocks provides <a href="/docs/2.0/loading/DataX-starrocks-writer">DataX-StarRocks-writer</a>
*StarRocks internal import. It is recommended to use <a href="/docs/2.0/loading/InsertInto">insert into tablename select</a> inside StarRocks, which can work with an external scheduler for simple ETL processing.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="basic-concepts">Basic Concepts<a href="#basic-concepts" class="hash-link" aria-label="Direct link to Basic Concepts" title="Direct link to Basic Concepts">​</a></h2>
<ul>
<li><strong>Import job</strong>: The import job reads the source data and performs cleaning and transformation, then imports the data into the StarRocks system. Once the import is complete, the data is ready to be queried.</li>
<li><strong>Label</strong>: Each import job has a unique label that identifies them. The label can be specified by the user or generated automatically by the system. The Label is unique within a database, i.e., it can be used for only one successful import job. The label cannot be used again unless the corresponding import job is failed. This mechanism ensures that the data corresponding to each label is imported At-Most-Once.</li>
<li><strong>Atomicity</strong>: All import methods in StarRocks provide atomicity guarantee, i.e. data within the same import job is either all valid or none;there is no data being partially imported. The valid data does not include data that is filtered due to data quality issues such as type conversion errors. See the data quality issues listed in the FAQ section.</li>
<li><strong>MySQL Protocol/HTTP Protocol</strong>: StarRocks provides two protocol interfaces: MySQL protocol and HTTP protocol. Some imports use the MySQL protocol interface to submit jobs, and others use the HTTP protocol interface instead.</li>
<li><strong>Broker Load</strong>: Reads data from external data sources (e.g. HDFS) and imports it to StarRocks. The Broker uses its own computational resources to pre-process the data for import.</li>
<li><strong>Spark  Load</strong>: StarRocks completes the import by reading an intermediate file that has been pre-processed and generated by an external resource such as Spark. This is an asynchronous import method – users need to initiate the import through the MySQL protocol and view the import result using the command.</li>
<li><strong>FE</strong>: Frontend, the node where StarRocks stores metadata and performs scheduling. It is mainly responsible for generating import execution plans and scheduling import jobs.</li>
<li><strong>BE</strong>: Backend, the computing and storage node of StarRocks. It is mainly responsible for the ETL and storage of data in the import process.</li>
<li><strong>Tablet</strong>: Logical partitioning of StarRocks tables. A table can be divided into multiple tablets according to partitioning and bucketing rules (refer to [Data Distribution](section <a href="/docs/2.0/table_design/Data_distribution">Data Distribution.md</a>)).</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="fundamentals">Fundamentals<a href="#fundamentals" class="hash-link" aria-label="Direct link to Fundamentals" title="Direct link to Fundamentals">​</a></h2>
<p>Import execution flow.</p>
<p><img loading="lazy" alt="import flow" src="/assets/images/4.1.2-a86ce8a3dcc8f792bd7f8b6971269403.png" width="1003" height="287" class="img_ev3q"></p>
<p>An import job is divided into five main phases.</p>
<ol>
<li>
<p><strong>PENDING</strong></p>
<p>Not required. This phase is when the user submits the import job and waits for the FE to schedule an execution.</p>
<p>This step is included in <code>Broker Load</code> and <code>Spark  Load</code>.</p>
</li>
<li>
<p><strong>ETL</strong></p>
<p>Not required. This phase performs pre-processing of data, including cleaning, partitioning, sorting, aggregation, and etc.</p>
<p>This step is included in <code>Spark Load</code>, which uses external computing resources to complete ETL.</p>
</li>
<li>
<p><strong>LOADING</strong></p>
<p>Data is first cleaned and converted in this stage, and then sent to the BE for processing. Now all data is imported and waiting to take effect, the status of the import job is <code>LOADING</code>.</p>
</li>
<li>
<p><strong>FINISHED</strong></p>
<p>After all data has taken effect, the status of the job becomes <code>FINISHED</code>. <code>FINISHED</code> is the final phase, after which the data can be queried.</p>
</li>
<li>
<p><strong>CANCELLED</strong></p>
<p>The job can be cancelled at any time before its status changes to <code>FINISHED</code>.</p>
</li>
</ol>
<p>Data import format：</p>
<ul>
<li>Integer (TINYINT, SMALLINT, INT, BIGINT, LARGEINT): <code>1, 1000, 1234</code></li>
<li>Floating-point (FLOAT, DOUBLE, DECIMAL): <code>1.1, 0.23, .356</code></li>
<li>Date (DATE, DATETIME): <code>2017-10-03, 2017-06-13 12:34:03</code></li>
<li>String (CHAR, VARCHAR): <code>I am a student, a</code></li>
<li>NULL value: <code>\N</code></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="import-method">Import method<a href="#import-method" class="hash-link" aria-label="Direct link to Import method" title="Direct link to Import method">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="introduction-of-import-methods">Introduction of import methods<a href="#introduction-of-import-methods" class="hash-link" aria-label="Direct link to Introduction of import methods" title="Direct link to Introduction of import methods">​</a></h3>
<p>StarRocks provides five import methods to support different data sources (such as HDFS, Kafka, local files, etc.) and different sync rules (asynchronous or synchronous).</p>
<p>All import methods support CSV data format. The <code>Broker Load</code> also supports parquet and ORC data formats.</p>
<ol>
<li>
<p><strong>Broker Load</strong></p>
<p><code>Broker Load</code> accesses and reads the external data source through the Broker process and then creates an import job to StarRocks using the MySQL protocol. The submitted job is executed asynchronously and the user can view the import results with the <code>SHOW LOAD</code> command.</p>
<p><code>Broker Load</code> is suitable for source data in storage systems that are accessible to the Broker process (e.g. HDFS). Supported data volume is up to tens to hundreds of GB of data.</p>
</li>
<li>
<p><strong>Spark Load</strong></p>
<p>To save computing resources and improve the performance of importing large data volumes, <code>Spark Load</code> enables pre-processing of data with external Spark resources. <code>Spark Load</code> is an asynchronous import method that requires to use the MySQL protocol to initiate import jobs. Users can view the import results with the <code>SHOW LOAD</code> command.</p>
<p><code>Spark Load</code> is suitable for initial migration of large data volumes (up to TB level) to StarRocks. The data needs to be stored in a Spark-accessible storage system (e.g. HDFS).</p>
</li>
<li>
<p><strong>Stream Load</strong></p>
<p><code>Stream Load</code> is a synchronous import method. Users can send a request via the HTTP protocol to import a local file or data stream into StarRocks and wait for the system to return the results to determine whether the import was successful.</p>
<p><code>Stream Load</code> is suitable for importing local files or importing data from a data stream through a program.</p>
</li>
<li>
<p><strong>Routine Load</strong></p>
<p>Routine Load automates data import from a specified data source. Users can submit a Routine Import job via the MySQL protocol, generating a resident thread that reads data from a data source (such as Kafka) and imports it into StarRocks without interruption.</p>
</li>
<li>
<p><strong>Insert into</strong></p>
<p>Similar to the <code>Insert</code> statement in MySQL, StarRocks provides <code>INSERT INTO tbl SELECT ... ;</code> to read data from a StarRocks table and import it to another table, and <code>INSERT INTO tbl VALUES(...) ;</code> to insert a single piece of data.</p>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="synchronous-and-asynchronous">Synchronous and Asynchronous<a href="#synchronous-and-asynchronous" class="hash-link" aria-label="Direct link to Synchronous and Asynchronous" title="Direct link to Synchronous and Asynchronous">​</a></h3>
<p>StarRocks currently has two types of import methods: synchronous and asynchronous.</p>
<blockquote>
<p>Note: If an external program accesses StarRocks&#x27;s import function, you need to determine which type of import method is used first, and then determine the access method.</p>
</blockquote>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="synchronous-import"><strong>Synchronous Import</strong><a href="#synchronous-import" class="hash-link" aria-label="Direct link to synchronous-import" title="Direct link to synchronous-import">​</a></h4>
<p>Synchronous import means that StarRocks executes synchronously while the user creates the import job and returns the result after the execution is finished.</p>
<p>The import methods of synchronous type are:<code>Stream  Load</code>and Insert.</p>
<p>Operational steps</p>
<ul>
<li>The user (external system) creates the import job.</li>
<li>StarRocks returns the import result.</li>
<li>The user (external system) views the import result. If the import result is a failure, the import job can be created again.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="asynchronous-import"><strong>Asynchronous Import</strong><a href="#asynchronous-import" class="hash-link" aria-label="Direct link to asynchronous-import" title="Direct link to asynchronous-import">​</a></h4>
<p>The asynchronous import method means that after the user creates the import job, StarRocks returns a confirmation message. The message does not mean that the data has been imported successfully. The import job will be executed asynchronously, and the user needs to send the view command to get the status. If the creation fails, the user should read the error message to determine whether the job needs to be created again.</p>
<p>The asynchronous types of import methods include<code>Broker Load</code> and <code>Spark Load</code>.</p>
<p><strong>Operational steps</strong>.</p>
<p>Step1: The user (external system) creates the import job.
Step2: StarRocks returns the result of the creation job.
Step3: If the job succeeds, go to step 4. If it fails, repeat from step 1.
Step4: The user (external system) polls to see the job status (FINISHED or CANCELLED).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="applicable-scenarios">Applicable scenarios<a href="#applicable-scenarios" class="hash-link" aria-label="Direct link to Applicable scenarios" title="Direct link to Applicable scenarios">​</a></h3>
<ol>
<li>
<p><strong>HDFS Import</strong></p>
<p>When the source data is stored in HDFS and the data volume is tens of GB to hundreds of GB, the <code>Broker Load</code> method can be used. Make sure that the deployed Broker has access to the HDFS data source. The import job is executed asynchronously, and users can view the result by <code>SHOW LOAD</code>.</p>
<p>When the source data is stored in HDFS and the data volume reaches the terabyte level, the <code>Spark  Load</code> method can be used. Make sure that the deployed Spark has access to the HDFS data source. The import job is executed asynchronously, and users can view the result by <code>SHOW LOAD</code>.</p>
<p>For other external data sources, as long as the Broker or Spark can read the data source, the corresponding method can also be used to import data.</p>
</li>
<li>
<p><strong>Local File Import</strong></p>
<p>When the source data is stored in local files and the data volume is less than 10GB, the <code>Stream  Load</code> method can be used to import data quickly. The HTTP protocol is used to create the import job. The job is executed synchronously, and the return value of the HTTP request will indicate the import result.</p>
</li>
<li>
<p><strong>Kafka Import</strong></p>
<p>When the data comes from a streaming data source such as Kafka and needs to be imported to StarRocks in real time, the <code>ROUTINE LOAD</code> method can be used. Users need to create routine import jobs via the MySQL protocol and StarRocks can continuously read and import data from Kafka.</p>
</li>
<li>
<p><strong>Insert Into Import</strong></p>
<p>When testing and processing temporary data, the <code>INSERT INTRO</code> method can be used to write data to StarRocks tables. Users can use<code>INSERT INTO tbl SELECT ...;</code>statement to read data from a StarRocks table and imports it into another table, and use <code>INSERT INTO tbl VALUES(...) ;</code>statement to insert a single piece of data into a specific table.</p>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="memory-limiting">Memory Limiting<a href="#memory-limiting" class="hash-link" aria-label="Direct link to Memory Limiting" title="Direct link to Memory Limiting">​</a></h2>
<p>To prevent imports from taking up too much memory and causing system OOM, users can set parameters to limit the memory consumed by import jobs. Different import methods limit memory in slightly different ways, see each import method for details.</p>
<p>An import job is usually distributed across multiple BEs. The memory parameters limit the memory usage of an import job on a single BE, not on the entire cluster.</p>
<p>Also, each BE sets the total memory limit that can be used for the import job. See the section &quot;4.1.5 General System Configuration&quot; for details. This configuration limits the overall memory usage for all import jobs running on that BE.</p>
<p>A stricter memory limit may affect the efficiency of the import, as the import process may frequently write data from memory to disk  when the memory limit is reached. However, an overly lenient memory limit may lead to system OOM when the import concurrency is high. In conclusion, the memory parameters need to be set properly based on  your requirements and use cases.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="general-system-configuration">General System Configuration<a href="#general-system-configuration" class="hash-link" aria-label="Direct link to General System Configuration" title="Direct link to General System Configuration">​</a></h2>
<p>This section explains the system configuration that is available for all import methods.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="fe-configuration"><strong>FE configuration</strong><a href="#fe-configuration" class="hash-link" aria-label="Direct link to fe-configuration" title="Direct link to fe-configuration">​</a></h3>
<p>The following system configurations belong to FE and can be modified by FE&#x27;s configuration file (<code>fe.conf</code>).</p>
<ul>
<li><code>max_load_timeout_second and min_load_timeout_second</code></li>
</ul>
<p>You can set the maximum and minimum range of values for the import timeout, both in seconds. The default maximum timeout is 3 days, and the minimum timeout is 1 second,. This parameter is common to all types of import jobs.</p>
<ul>
<li><code>desired_max_waiting_jobs</code></li>
</ul>
<p>The default value for the maximum number of import jobs that can be held in the waiting queue is 100. If the number of PENDING import jobs in the FE reaches this value, new import requests will be rejected. This configuration is valid only for asynchronous imports.</p>
<ul>
<li><code>max_running_txn_num_per_db</code></li>
</ul>
<p>The default value for the maximum number of running import jobs in each database (regardless of import type) is 100. When the number of running import jobs exceeds this value subsequent imports will not be executed. If it is a synchronous job, the job will be rejected; if it is an asynchronous job, the job will wait in the queue.</p>
<ul>
<li><code>label_keep_max_second</code></li>
</ul>
<p>This parameter determines how long the records of completed (FINISHED or CANCELLED) import jobs  can be kept in the StarRocks. The default is 3 days. This parameter is common for all types of import jobs.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="be-configuration"><strong>BE configuration</strong><a href="#be-configuration" class="hash-link" aria-label="Direct link to be-configuration" title="Direct link to be-configuration">​</a></h3>
<p>The following belongs to the system configuration of BE, which can be modified by the BE configuration file (<code>be.conf)</code>.</p>
<ul>
<li><code>push_write_mbytes_per_sec</code></li>
</ul>
<p>Write speed limit for a single Tablet on BE. The default value is 10, i.e. 10MB/s. The maximum write speed is usually 10-30MB/s, depending on the schema and the system. This parameter can be adjusted to control the import speed.</p>
<ul>
<li><code>write_buffer_size</code></li>
</ul>
<p>Imported data is first written to a memory block on the BE, and then written to disk only if this memory block reaches its threshold (100MB by default). Too small a threshold may result in a large number of small files on the BE. This threshold can be increased to reduce the number of files. However, too large a threshold may lead to RPC timeouts, see the configuration note below.</p>
<ul>
<li>`tablet_writer_rpc_timeout_sec</li>
</ul>
<p>The RPC timeout for sending a batch (1024 rows) is 600 seconds by default. Because this RPC may involve write operation of multiple memory blocks, it may lead to RPC timeouts (such as send batch fail errors).This can be avoided by adjusting the parameter appropriately. Also, if you adjust the <code>write_buffer_size</code> configuration, you need to adjust this parameter accordingly.</p>
<ul>
<li><code>streaming_load_rpc_max_alive_time_sec</code></li>
</ul>
<p>During the import process, StarRocks opens a writer for each tablet to receive and write data. This parameter specifies the timeout for the writer to wait. The default value is 600 seconds. If the Writer does not receive any data within the time specified by the parameter, the writer will be automatically destroyed. If the system processing speed is slow, the writer may not receive the next batch of data any soon, resulting in an import error <code>TabletWriter add batch with unknown id</code>.</p>
<ul>
<li><code>load_process_max_memory_limit_bytes</code> and <code>load_process_max_memory_limit_percent</code></li>
</ul>
<p>These two parameters are maximum memory and maximum memory percentage, respectively, limiting the maximum amount of memory that can be used for import jobs on a single BE. The system will take the smaller value of the two parameters as the memory usage limit.</p>
<p>*<code>load_process_max_memory_limit_percent</code></p>
<p>The percentage of the total memory limit for a BE is 80 by default. (The total memory limit <code>mem_limit</code> defaults to 80%, indicating the percentage to its physical memory). That is, assuming the physical memory is M, the default import memory limit is <code>M * 80% * 80%</code>.</p>
<ul>
<li><code>load_process_max_memory_limit_bytes</code>  is100GB by default.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="guidelines">Guidelines<a href="#guidelines" class="hash-link" aria-label="Direct link to Guidelines" title="Direct link to Guidelines">​</a></h2>
<p>When users import data to StarRocks, they usually use programmatic docking. The following are some guidelines.</p>
<ol>
<li>Choose the appropriate import method: choose the import method according to the data size, import frequency and data source. For example, if the original data is stored on HDFS, use <code>Broker Load</code> to import.</li>
<li>Confirm the protocol of the import method: If you choose <code>Broker Load</code>, the external system needs to be able to submit and view the import jobs regularly using the MySQL protocol.</li>
<li>Confirm the type of import method: The import method can be synchronous or asynchronous. If the import is asynchronous, the external system must invoke the <code>show load</code> command to see whether the import is successful.</li>
<li>Develop a Label generation strategy: The Label generation strategy must meet the principle of uniqueness and fixity for each batch of data.</li>
<li>Ensure Exactly-Once: External system needs to ensure At-Least-Once of data import. StarRocks&#x27;s Label mechanism can ensure At-Most-Once of data import, so that the overall data import can be guaranteed Exactly-Once.</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="faqs">FAQs<a href="#faqs" class="hash-link" aria-label="Direct link to FAQs" title="Direct link to FAQs">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="label-already-exists"><strong>Label Already Exists</strong><a href="#label-already-exists" class="hash-link" aria-label="Direct link to label-already-exists" title="Direct link to label-already-exists">​</a></h3>
<p>This means that an import job with the same Label has been successfully imported or is being executed in the same database. Users need to check if there is a Label conflict between different import methods or if the job has been submitted repeatedly. The steps to check for Label duplicates are as follows.</p>
<ul>
<li>Since the import Label in the StarRocks system does not distinguish between import methods, there is an issue with other import methods using the same Label.</li>
<li>Check if a <code>FINISHED</code> import job with the same Label already exists by <code>SHOW LOAD WHERE LABEL = &quot;xxx&quot;</code>, where xxx is the Label string to be checked.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="error-reported-for-data-quality-issue-etl_quality_unsatisfied-msgquality-not-good-enough-to-cancel"><strong>Error reported for data quality issue</strong>: <code>ETL_QUALITY_UNSATISFIED; msg:quality not good enough to cancel</code><a href="#error-reported-for-data-quality-issue-etl_quality_unsatisfied-msgquality-not-good-enough-to-cancel" class="hash-link" aria-label="Direct link to error-reported-for-data-quality-issue-etl_quality_unsatisfied-msgquality-not-good-enough-to-cancel" title="Direct link to error-reported-for-data-quality-issue-etl_quality_unsatisfied-msgquality-not-good-enough-to-cancel">​</a></h3>
<p>Error data can be viewed by URL in <code>SHOW LOAD</code>. Common types of errors are:</p>
<ul>
<li><code>convert csv string to INT failed</code>. The error occurs when converting the string to the corresponding type, for example, when converting &quot;abc&quot; to a number.</li>
<li><code>the length of input is too long than schema.</code> The length is incorrect, such as a fixed-length string exceeding the length set in the table, or an int exceeding 4 bytes.</li>
<li><code>actual column number is less than schema column number.</code> The number of columns in a row of the import file is less than the specified number of columns after the specified delimiter, probably because the delimiter is incorrect.</li>
<li><code>The actual column number is more than schema column number.</code> The number of columns in a row of the import file is bigger than the specified number of columns after the specified delimiter.</li>
<li><code>The frac part length longer than schema scale.</code> The fractional part of a decimal column in the import file is longer than the specified length.</li>
<li><code>The int part length longer than schema precision.</code> The length of the integer part of a decimal column in the imported file exceeds the specified length.</li>
<li><code>The length of decimal value is overflow.</code> The length of a decimal column in the import file exceeds the specified length.</li>
<li><code>There is no corresponding partition for this key.</code> The value of the partition column in a row of the import file is not within the partition range.</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/StarRocks/starrocks/edit/main/docs/loading/Loading_intro.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/2.0/loading/Json_loading"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Introduction</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/2.0/loading/RoutineLoad"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Routine Load</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#basic-concepts" class="table-of-contents__link toc-highlight">Basic Concepts</a></li><li><a href="#fundamentals" class="table-of-contents__link toc-highlight">Fundamentals</a></li><li><a href="#import-method" class="table-of-contents__link toc-highlight">Import method</a><ul><li><a href="#introduction-of-import-methods" class="table-of-contents__link toc-highlight">Introduction of import methods</a></li><li><a href="#synchronous-and-asynchronous" class="table-of-contents__link toc-highlight">Synchronous and Asynchronous</a></li><li><a href="#applicable-scenarios" class="table-of-contents__link toc-highlight">Applicable scenarios</a></li></ul></li><li><a href="#memory-limiting" class="table-of-contents__link toc-highlight">Memory Limiting</a></li><li><a href="#general-system-configuration" class="table-of-contents__link toc-highlight">General System Configuration</a><ul><li><a href="#fe-configuration" class="table-of-contents__link toc-highlight"><strong>FE configuration</strong></a></li><li><a href="#be-configuration" class="table-of-contents__link toc-highlight"><strong>BE configuration</strong></a></li></ul></li><li><a href="#guidelines" class="table-of-contents__link toc-highlight">Guidelines</a></li><li><a href="#faqs" class="table-of-contents__link toc-highlight">FAQs</a><ul><li><a href="#label-already-exists" class="table-of-contents__link toc-highlight"><strong>Label Already Exists</strong></a></li><li><a href="#error-reported-for-data-quality-issue-etl_quality_unsatisfied-msgquality-not-good-enough-to-cancel" class="table-of-contents__link toc-highlight"><strong>Error reported for data quality issue</strong>: <code>ETL_QUALITY_UNSATISFIED; msg:quality not good enough to cancel</code></a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/introduction/StarRocks_intro">Documentation</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 StarRocks, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>